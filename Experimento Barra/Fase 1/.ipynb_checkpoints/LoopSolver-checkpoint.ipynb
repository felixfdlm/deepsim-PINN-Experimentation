{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlPRqY9RIhDa"
   },
   "source": [
    "# Paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bj9aqM-EIVDt",
    "outputId": "c90f9f34-575b-43f7-965e-f6da902b04bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-07-28 10:36:11 +02:00)\n"
     ]
    }
   ],
   "source": [
    "# !pip install sciann --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xH-CR3upIoF1",
    "outputId": "6f0571a3-4c2e-42bc-f30d-87ac75632f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-07-28 10:36:12 +02:00)\n"
     ]
    }
   ],
   "source": [
    "# !pip install mlflow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1O82sOhMIqYb",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- SCIANN 0.6.4.2 ---------------------- \n",
      "For details, check out our review paper and the documentation at: \n",
      " +  \"https://www.sciencedirect.com/science/article/pii/S0045782520307374\", \n",
      " +  \"https://arxiv.org/abs/2005.08803\", \n",
      " +  \"https://www.sciann.com\". \n",
      "\n",
      " Need support or would like to contribute, please join sciann`s slack group: \n",
      " +  \"https://join.slack.com/t/sciann/shared_invite/zt-ne1f5jlx-k_dY8RGo3ZreDXwz0f~CeA\" \n",
      " \n",
      "TensorFlow Version: 2.3.0 \n",
      "Python Version: 3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)] \n",
      "\n",
      "time: 0 ns (started: 2021-08-03 09:34:36 +02:00)\n"
     ]
    }
   ],
   "source": [
    "#Paquetes para modelos\n",
    "import sciann as sn\n",
    "import numpy as np\n",
    "from sciann.utils.math import diff, sign, sin, exp\n",
    "from sciann.utils import math as scmath\n",
    "import tensorflow as tf \n",
    "\n",
    "#MlFlow\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_param\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import time\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKzQmbGe-6dA"
   },
   "source": [
    "#  Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1Jx3eGrI1lm"
   },
   "source": [
    "## Modelo simbólico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EDEY72QFIuyo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-08-03 09:34:36 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def u_n(n,x,t):\n",
    "  mu_n = (2*n+1)*np.pi/4\n",
    "  T_n =  np.exp(-t*(mu_n**2))\n",
    "  X_n = -np.cos(mu_n*x)*2.5/(mu_n**2)\n",
    "  return X_n*T_n\n",
    "\n",
    "profundidad = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89pZ6XKiFENM"
   },
   "source": [
    "## Mallado del test (estático)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4M1_v5imFDlf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2021-08-03 09:34:36 +02:00)\n"
     ]
    }
   ],
   "source": [
    "denspt = 50 # Densidad de puntos de evaluación de los funcionales\n",
    "xmin,xmax=0,2 # Límites en x e y\n",
    "tmin,tmax=0,10 # Límites en tiempo t\n",
    "xrange=xmax-xmin\n",
    "trange=tmax-tmin\n",
    "\n",
    "x_test, t_test = np.meshgrid(\n",
    "    np.linspace(xmin, xmax, xrange*denspt), \n",
    "    np.arange(0,10*50)/50.\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OXc7C6doGYt0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 312 ms (started: 2021-08-03 09:34:36 +02:00)\n"
     ]
    }
   ],
   "source": [
    "#Predicciones del simbólico\n",
    "u_pred_Simb = np.sum((np.array([u_n(n,x_test,t_test) for n in range(profundidad)])),axis=0)+5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SC7Vr6qdBco3"
   },
   "source": [
    "## Wrappers en forma de funciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ohZraM86BbhJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-08-03 09:34:37 +02:00)\n"
     ]
    }
   ],
   "source": [
    "# Activación para los bordes\n",
    "\n",
    "def activacion(coord,location,direction):\n",
    "    return (1-sign(direction*(location-coord)))/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lnGCAakByRi"
   },
   "source": [
    "## Constantes del problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fGkJ25PbBxwz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-08-03 09:34:37 +02:00)\n"
     ]
    }
   ],
   "source": [
    "TOL = 0.05 # Esta constante se usa para que los bordes tomen valores y se activen las funciones de contorno\n",
    "conveccion = 25. # Coeficiente de pérdida de calor en los bordes y=1 e y=-1\n",
    "conductividad = 1. # Capacidad conductora de calor del material de la placa\n",
    "capCal = 1. # Capacidad de retención de calor del material de la placa\n",
    "focoTemp = 25. # Temperatura del foco de calor\n",
    "tempExt = 5. # Temperatura del exterior\n",
    "tempInicial = 0. # Temperatura inicial de la placa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKFbGYLTKJQu"
   },
   "source": [
    "# Mallado de parámetros de experimentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lyl2OdcaKL3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "time: 0 ns (started: 2021-08-03 09:34:38 +02:00)\n"
     ]
    }
   ],
   "source": [
    "trainpt = [50]\n",
    "u_Structure = [3*[100], 5*[50], 50*[10], 100*[5], 5*[5], 20*[20], 50*[50]]\n",
    "u_Activator = ['tanh']\n",
    "epochs = [200, 1000, 2500]\n",
    "loss = ['mse']\n",
    "optimizer = ['Adam']\n",
    "batch_size = [5000, 10000, 25000]\n",
    "\n",
    "\n",
    "configuraciones = list(product(trainpt,u_Structure,u_Activator,epochs,loss,optimizer,batch_size))\n",
    "configuraciones = [list(configuracion) for configuracion in configuraciones]\n",
    "configuraciones_finalizadas = list([])\n",
    "\n",
    "print(len(configuraciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ma08un-SLyl5",
    "outputId": "6fe6f7ef-f2c6-45f2-d148-f527639fc15c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "time: 31 ms (started: 2021-08-03 13:46:00 +02:00)\n"
     ]
    }
   ],
   "source": [
    "configuraciones_finalizadas = np.load('configuraciones_finalizadas.npy',allow_pickle=True).tolist()\n",
    "configuraciones_restantes = [configuracion for configuracion in configuraciones if configuracion not in configuraciones_finalizadas]\n",
    "print(len(configuraciones_restantes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eU6ME59FBHzk"
   },
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9NXdlcBApGf",
    "outputId": "9b856049-5b8a-44bd-b590-420369c6a880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 50000 \n",
      "Batch size: 5000 \n",
      "Total batches: 10 \n",
      "\n",
      "Epoch 1/2500\n",
      "10/10 [==============================] - 2s 193ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.9526 - u_loss: 11.9512 - sub_4_loss: 0.0014 - mul_24_loss: 6.3858e-06\n",
      "Epoch 2/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.5879 - u_loss: 1.5879 - sub_4_loss: 5.7687e-08 - mul_24_loss: 2.3032e-10\n",
      "Epoch 3/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.4420 - u_loss: 1.4420 - sub_4_loss: 7.3135e-11 - mul_24_loss: 2.2876e-12\n",
      "Epoch 4/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2465 - u_loss: 1.2465 - sub_4_loss: 7.4875e-10 - mul_24_loss: 1.6018e-11\n",
      "Epoch 5/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2588 - u_loss: 1.2588 - sub_4_loss: 9.4749e-10 - mul_24_loss: 1.8378e-11\n",
      "Epoch 6/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2285 - u_loss: 1.2285 - sub_4_loss: 3.5299e-10 - mul_24_loss: 7.4728e-12\n",
      "Epoch 7/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2305 - u_loss: 1.2305 - sub_4_loss: 2.7617e-10 - mul_24_loss: 6.0581e-12\n",
      "Epoch 8/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2280 - u_loss: 1.2280 - sub_4_loss: 2.6253e-10 - mul_24_loss: 5.7917e-12\n",
      "Epoch 9/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2287 - u_loss: 1.2287 - sub_4_loss: 2.1727e-10 - mul_24_loss: 4.9472e-12\n",
      "Epoch 10/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2309 - u_loss: 1.2309 - sub_4_loss: 2.2438e-10 - mul_24_loss: 5.0881e-12\n",
      "Epoch 11/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2295 - u_loss: 1.2295 - sub_4_loss: 1.8276e-10 - mul_24_loss: 4.2208e-12\n",
      "Epoch 12/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2294 - u_loss: 1.2294 - sub_4_loss: 1.6781e-10 - mul_24_loss: 4.0003e-12\n",
      "Epoch 13/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2305 - u_loss: 1.2305 - sub_4_loss: 1.5969e-10 - mul_24_loss: 3.7687e-12\n",
      "Epoch 14/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2313 - u_loss: 1.2313 - sub_4_loss: 1.5130e-10 - mul_24_loss: 3.6673e-12\n",
      "Epoch 15/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2293 - u_loss: 1.2293 - sub_4_loss: 1.1286e-10 - mul_24_loss: 2.8990e-12\n",
      "Epoch 16/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2286 - u_loss: 1.2286 - sub_4_loss: 1.0310e-10 - mul_24_loss: 2.6728e-12\n",
      "Epoch 17/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2283 - u_loss: 1.2283 - sub_4_loss: 1.0025e-10 - mul_24_loss: 2.6245e-12\n",
      "Epoch 18/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2281 - u_loss: 1.2281 - sub_4_loss: 8.4678e-11 - mul_24_loss: 2.2800e-12\n",
      "Epoch 19/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2289 - u_loss: 1.2289 - sub_4_loss: 7.8907e-11 - mul_24_loss: 2.1532e-12\n",
      "Epoch 20/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2296 - u_loss: 1.2296 - sub_4_loss: 6.6554e-11 - mul_24_loss: 1.8702e-12\n",
      "Epoch 21/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2325 - u_loss: 1.2325 - sub_4_loss: 6.9512e-11 - mul_24_loss: 1.9466e-12\n",
      "Epoch 22/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2312 - u_loss: 1.2312 - sub_4_loss: 3.7997e-11 - mul_24_loss: 1.1617e-12\n",
      "Epoch 23/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2301 - u_loss: 1.2301 - sub_4_loss: 4.4906e-11 - mul_24_loss: 1.3332e-12\n",
      "Epoch 24/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2284 - u_loss: 1.2284 - sub_4_loss: 2.8903e-11 - mul_24_loss: 9.3271e-13\n",
      "Epoch 25/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2281 - u_loss: 1.2281 - sub_4_loss: 2.4176e-11 - mul_24_loss: 7.8917e-13\n",
      "Epoch 26/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2310 - u_loss: 1.2310 - sub_4_loss: 2.3315e-11 - mul_24_loss: 7.3859e-13\n",
      "Epoch 27/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2287 - u_loss: 1.2287 - sub_4_loss: 1.9972e-11 - mul_24_loss: 6.3510e-13\n",
      "Epoch 28/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2301 - u_loss: 1.2301 - sub_4_loss: 1.5277e-11 - mul_24_loss: 4.1966e-13\n",
      "Epoch 29/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2281 - u_loss: 1.2281 - sub_4_loss: 1.4998e-11 - mul_24_loss: 4.1885e-13\n",
      "Epoch 30/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2313 - u_loss: 1.2313 - sub_4_loss: 1.4764e-11 - mul_24_loss: 3.6898e-13\n",
      "Epoch 31/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2319 - u_loss: 1.2319 - sub_4_loss: 1.3438e-11 - mul_24_loss: 2.0329e-13\n",
      "Epoch 32/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2343 - u_loss: 1.2343 - sub_4_loss: 1.6490e-11 - mul_24_loss: 1.4654e-13\n",
      "Epoch 33/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2344 - u_loss: 1.2344 - sub_4_loss: 1.6157e-11 - mul_24_loss: 1.1996e-13\n",
      "Epoch 34/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2280 - u_loss: 1.2280 - sub_4_loss: 1.9401e-11 - mul_24_loss: 5.7768e-14\n",
      "Epoch 35/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2294 - u_loss: 1.2294 - sub_4_loss: 2.5148e-11 - mul_24_loss: 3.0220e-14\n",
      "Epoch 36/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2276 - u_loss: 1.2276 - sub_4_loss: 2.5710e-11 - mul_24_loss: 3.3466e-14\n",
      "Epoch 37/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2282 - u_loss: 1.2282 - sub_4_loss: 2.9508e-11 - mul_24_loss: 2.9644e-14\n",
      "Epoch 38/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2297 - u_loss: 1.2297 - sub_4_loss: 3.7444e-11 - mul_24_loss: 4.4625e-14\n",
      "Epoch 39/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2314 - u_loss: 1.2314 - sub_4_loss: 3.6971e-11 - mul_24_loss: 4.2548e-14\n",
      "Epoch 40/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2295 - u_loss: 1.2295 - sub_4_loss: 4.7361e-11 - mul_24_loss: 8.2042e-14\n",
      "Epoch 41/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2287 - u_loss: 1.2287 - sub_4_loss: 5.1140e-11 - mul_24_loss: 1.0069e-13\n",
      "Epoch 42/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2284 - u_loss: 1.2284 - sub_4_loss: 5.7547e-11 - mul_24_loss: 1.3493e-13\n",
      "Epoch 43/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2285 - u_loss: 1.2285 - sub_4_loss: 6.3300e-11 - mul_24_loss: 1.7167e-13\n",
      "Epoch 44/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2301 - u_loss: 1.2301 - sub_4_loss: 7.1205e-11 - mul_24_loss: 2.2331e-13\n",
      "Epoch 45/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2304 - u_loss: 1.2304 - sub_4_loss: 8.1691e-11 - mul_24_loss: 3.0095e-13\n",
      "Epoch 46/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2333 - u_loss: 1.2333 - sub_4_loss: 8.3391e-11 - mul_24_loss: 3.0449e-13\n",
      "Epoch 47/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2281 - u_loss: 1.2281 - sub_4_loss: 9.5817e-11 - mul_24_loss: 4.1072e-13\n",
      "Epoch 48/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2309 - u_loss: 1.2309 - sub_4_loss: 1.0256e-10 - mul_24_loss: 4.6288e-13\n",
      "Epoch 49/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2306 - u_loss: 1.2306 - sub_4_loss: 1.1622e-10 - mul_24_loss: 5.9295e-13\n",
      "Epoch 50/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2301 - u_loss: 1.2301 - sub_4_loss: 1.1922e-10 - mul_24_loss: 6.0387e-13\n",
      "Epoch 51/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2286 - u_loss: 1.2286 - sub_4_loss: 1.3142e-10 - mul_24_loss: 7.1973e-13\n",
      "Epoch 52/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2287 - u_loss: 1.2287 - sub_4_loss: 1.4016e-10 - mul_24_loss: 7.9944e-13\n",
      "Epoch 53/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2283 - u_loss: 1.2283 - sub_4_loss: 1.4897e-10 - mul_24_loss: 8.7775e-13\n",
      "Epoch 54/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2306 - u_loss: 1.2306 - sub_4_loss: 1.5711e-10 - mul_24_loss: 9.4727e-13\n",
      "Epoch 55/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2272 - u_loss: 1.2272 - sub_4_loss: 1.6917e-10 - mul_24_loss: 1.0791e-12\n",
      "Epoch 56/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2296 - u_loss: 1.2296 - sub_4_loss: 1.7757e-10 - mul_24_loss: 1.1504e-12\n",
      "Epoch 57/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2293 - u_loss: 1.2293 - sub_4_loss: 1.8991e-10 - mul_24_loss: 1.2797e-12\n",
      "Epoch 58/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2286 - u_loss: 1.2286 - sub_4_loss: 1.9697e-10 - mul_24_loss: 1.3386e-12\n",
      "Epoch 59/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2279 - u_loss: 1.2279 - sub_4_loss: 2.0917e-10 - mul_24_loss: 1.4699e-12\n",
      "Epoch 60/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2281 - u_loss: 1.2281 - sub_4_loss: 2.2092e-10 - mul_24_loss: 1.5895e-12\n",
      "Epoch 61/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2285 - u_loss: 1.2285 - sub_4_loss: 2.3089e-10 - mul_24_loss: 1.6815e-12\n",
      "Epoch 62/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2281 - u_loss: 1.2281 - sub_4_loss: 2.4266e-10 - mul_24_loss: 1.8154e-12\n",
      "Epoch 63/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2295 - u_loss: 1.2295 - sub_4_loss: 2.5612e-10 - mul_24_loss: 1.9350e-12\n",
      "Epoch 64/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2279 - u_loss: 1.2279 - sub_4_loss: 2.6627e-10 - mul_24_loss: 2.0577e-12\n",
      "Epoch 65/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2288 - u_loss: 1.2288 - sub_4_loss: 2.7912e-10 - mul_24_loss: 2.1921e-12\n",
      "Epoch 66/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2289 - u_loss: 1.2289 - sub_4_loss: 2.9141e-10 - mul_24_loss: 2.3311e-12\n",
      "Epoch 67/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2304 - u_loss: 1.2304 - sub_4_loss: 3.0699e-10 - mul_24_loss: 2.4832e-12\n",
      "Epoch 68/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2301 - u_loss: 1.2301 - sub_4_loss: 3.1724e-10 - mul_24_loss: 2.6242e-12\n",
      "Epoch 69/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2295 - u_loss: 1.2295 - sub_4_loss: 3.3397e-10 - mul_24_loss: 2.7896e-12\n",
      "Epoch 70/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2337 - u_loss: 1.2337 - sub_4_loss: 3.4627e-10 - mul_24_loss: 2.9315e-12\n",
      "Epoch 71/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2282 - u_loss: 1.2282 - sub_4_loss: 3.6459e-10 - mul_24_loss: 3.1204e-12\n",
      "Epoch 72/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2286 - u_loss: 1.2286 - sub_4_loss: 3.7716e-10 - mul_24_loss: 3.2724e-12\n",
      "Epoch 73/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2299 - u_loss: 1.2299 - sub_4_loss: 3.9085e-10 - mul_24_loss: 3.4275e-12\n",
      "Epoch 74/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2276 - u_loss: 1.2276 - sub_4_loss: 4.0796e-10 - mul_24_loss: 3.6171e-12\n",
      "Epoch 75/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2399 - u_loss: 1.2399 - sub_4_loss: 4.3169e-10 - mul_24_loss: 3.8551e-12\n",
      "Epoch 76/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2408 - u_loss: 1.2408 - sub_4_loss: 4.1160e-10 - mul_24_loss: 3.7417e-12\n",
      "Epoch 77/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2378 - u_loss: 1.2378 - sub_4_loss: 4.5329e-10 - mul_24_loss: 4.1406e-12\n",
      "Epoch 78/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2280 - u_loss: 1.2280 - sub_4_loss: 4.4487e-10 - mul_24_loss: 4.0653e-12\n",
      "Epoch 79/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2316 - u_loss: 1.2316 - sub_4_loss: 4.6763e-10 - mul_24_loss: 4.3061e-12\n",
      "Epoch 80/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2291 - u_loss: 1.2291 - sub_4_loss: 4.7088e-10 - mul_24_loss: 4.3562e-12\n",
      "Epoch 81/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2289 - u_loss: 1.2289 - sub_4_loss: 4.8184e-10 - mul_24_loss: 4.4886e-12\n",
      "Epoch 82/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2282 - u_loss: 1.2282 - sub_4_loss: 5.0796e-10 - mul_24_loss: 4.7654e-12\n",
      "Epoch 83/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2280 - u_loss: 1.2280 - sub_4_loss: 5.1800e-10 - mul_24_loss: 4.8884e-12\n",
      "Epoch 84/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2284 - u_loss: 1.2284 - sub_4_loss: 5.2739e-10 - mul_24_loss: 5.0185e-12\n",
      "Epoch 85/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2283 - u_loss: 1.2283 - sub_4_loss: 5.5098e-10 - mul_24_loss: 5.2808e-12\n",
      "Epoch 86/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2312 - u_loss: 1.2312 - sub_4_loss: 5.6846e-10 - mul_24_loss: 5.4904e-12\n",
      "Epoch 87/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2379 - u_loss: 1.2379 - sub_4_loss: 5.6313e-10 - mul_24_loss: 5.4498e-12\n",
      "Epoch 88/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2385 - u_loss: 1.2385 - sub_4_loss: 6.1149e-10 - mul_24_loss: 5.9594e-12\n",
      "Epoch 89/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2299 - u_loss: 1.2299 - sub_4_loss: 5.8463e-10 - mul_24_loss: 5.6978e-12\n",
      "Epoch 90/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2304 - u_loss: 1.2304 - sub_4_loss: 6.2534e-10 - mul_24_loss: 6.1434e-12\n",
      "Epoch 91/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2323 - u_loss: 1.2323 - sub_4_loss: 6.1021e-10 - mul_24_loss: 6.0152e-12\n",
      "Epoch 92/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2287 - u_loss: 1.2287 - sub_4_loss: 6.5285e-10 - mul_24_loss: 6.4721e-12\n",
      "Epoch 93/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2286 - u_loss: 1.2286 - sub_4_loss: 6.4612e-10 - mul_24_loss: 6.4412e-12\n",
      "Epoch 94/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2293 - u_loss: 1.2293 - sub_4_loss: 6.7946e-10 - mul_24_loss: 6.8133e-12\n",
      "Epoch 95/2500\n",
      "10/10 [==============================] - 2s 156ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2286 - u_loss: 1.2286 - sub_4_loss: 6.7762e-10 - mul_24_loss: 6.8311e-12\n",
      "Epoch 96/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2295 - u_loss: 1.2295 - sub_4_loss: 7.2947e-10 - mul_24_loss: 7.4014e-12\n",
      "Epoch 97/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2300 - u_loss: 1.2300 - sub_4_loss: 7.0754e-10 - mul_24_loss: 7.2289e-12\n",
      "Epoch 98/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2306 - u_loss: 1.2306 - sub_4_loss: 7.6599e-10 - mul_24_loss: 7.8920e-12\n",
      "Epoch 99/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2328 - u_loss: 1.2328 - sub_4_loss: 7.3588e-10 - mul_24_loss: 7.6033e-12\n",
      "Epoch 100/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2292 - u_loss: 1.2292 - sub_4_loss: 7.9874e-10 - mul_24_loss: 8.3130e-12\n",
      "Epoch 101/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2286 - u_loss: 1.2286 - sub_4_loss: 7.9713e-10 - mul_24_loss: 8.3473e-12\n",
      "Epoch 102/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2285 - u_loss: 1.2285 - sub_4_loss: 8.1189e-10 - mul_24_loss: 8.5464e-12\n",
      "Epoch 103/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2284 - u_loss: 1.2284 - sub_4_loss: 8.6354e-10 - mul_24_loss: 9.1680e-12\n",
      "Epoch 104/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2298 - u_loss: 1.2298 - sub_4_loss: 8.4727e-10 - mul_24_loss: 9.0450e-12\n",
      "Epoch 105/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2322 - u_loss: 1.2322 - sub_4_loss: 9.2270e-10 - mul_24_loss: 9.9476e-12\n",
      "Epoch 106/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2293 - u_loss: 1.2293 - sub_4_loss: 9.1125e-10 - mul_24_loss: 9.8578e-12\n",
      "Epoch 107/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2285 - u_loss: 1.2285 - sub_4_loss: 9.3710e-10 - mul_24_loss: 1.0231e-11\n",
      "Epoch 108/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2291 - u_loss: 1.2291 - sub_4_loss: 9.6398e-10 - mul_24_loss: 1.0616e-11\n",
      "Epoch 109/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2301 - u_loss: 1.2301 - sub_4_loss: 1.0342e-09 - mul_24_loss: 1.1469e-11\n",
      "Epoch 110/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2303 - u_loss: 1.2303 - sub_4_loss: 9.8596e-10 - mul_24_loss: 1.0987e-11\n",
      "Epoch 111/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2313 - u_loss: 1.2313 - sub_4_loss: 1.1258e-09 - mul_24_loss: 1.2682e-11\n",
      "Epoch 112/2500\n",
      "10/10 [==============================] - 2s 157ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2325 - u_loss: 1.2325 - sub_4_loss: 1.0269e-09 - mul_24_loss: 1.1663e-11\n",
      "Epoch 113/2500\n",
      "10/10 [==============================] - 2s 159ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2296 - u_loss: 1.2296 - sub_4_loss: 1.1498e-09 - mul_24_loss: 1.3120e-11\n",
      "Epoch 114/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2277 - u_loss: 1.2277 - sub_4_loss: 1.1489e-09 - mul_24_loss: 1.3199e-11\n",
      "Epoch 115/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2293 - u_loss: 1.2293 - sub_4_loss: 1.1499e-09 - mul_24_loss: 1.3309e-11\n",
      "Epoch 116/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2328 - u_loss: 1.2328 - sub_4_loss: 1.2600e-09 - mul_24_loss: 1.4728e-11\n",
      "Epoch 117/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2294 - u_loss: 1.2294 - sub_4_loss: 1.2068e-09 - mul_24_loss: 1.4192e-11\n",
      "Epoch 118/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2303 - u_loss: 1.2303 - sub_4_loss: 1.3332e-09 - mul_24_loss: 1.5778e-11\n",
      "Epoch 119/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2314 - u_loss: 1.2314 - sub_4_loss: 1.2649e-09 - mul_24_loss: 1.5143e-11\n",
      "Epoch 120/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2321 - u_loss: 1.2321 - sub_4_loss: 1.4933e-09 - mul_24_loss: 1.8001e-11\n",
      "Epoch 121/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2384 - u_loss: 1.2384 - sub_4_loss: 1.3101e-09 - mul_24_loss: 1.5997e-11\n",
      "Epoch 122/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2294 - u_loss: 1.2294 - sub_4_loss: 1.3930e-09 - mul_24_loss: 1.7112e-11\n",
      "Epoch 123/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2304 - u_loss: 1.2304 - sub_4_loss: 1.4538e-09 - mul_24_loss: 1.7945e-11\n",
      "Epoch 124/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2295 - u_loss: 1.2295 - sub_4_loss: 1.5264e-09 - mul_24_loss: 1.9021e-11\n",
      "Epoch 125/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2285 - u_loss: 1.2285 - sub_4_loss: 1.6267e-09 - mul_24_loss: 2.0474e-11\n",
      "Epoch 126/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2327 - u_loss: 1.2327 - sub_4_loss: 1.5119e-09 - mul_24_loss: 1.9151e-11\n",
      "Epoch 127/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2325 - u_loss: 1.2325 - sub_4_loss: 1.7848e-09 - mul_24_loss: 2.2922e-11\n",
      "Epoch 128/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2323 - u_loss: 1.2323 - sub_4_loss: 1.6382e-09 - mul_24_loss: 2.1237e-11\n",
      "Epoch 129/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2293 - u_loss: 1.2293 - sub_4_loss: 1.9112e-09 - mul_24_loss: 2.4943e-11\n",
      "Epoch 130/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2296 - u_loss: 1.2296 - sub_4_loss: 1.8226e-09 - mul_24_loss: 2.4071e-11\n",
      "Epoch 131/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2288 - u_loss: 1.2288 - sub_4_loss: 1.9922e-09 - mul_24_loss: 2.6517e-11\n",
      "Epoch 132/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2277 - u_loss: 1.2277 - sub_4_loss: 2.0523e-09 - mul_24_loss: 2.7640e-11\n",
      "Epoch 133/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2288 - u_loss: 1.2288 - sub_4_loss: 2.1472e-09 - mul_24_loss: 2.9236e-11\n",
      "Epoch 134/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2373 - u_loss: 1.2373 - sub_4_loss: 2.5787e-09 - mul_24_loss: 3.5384e-11\n",
      "Epoch 135/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2355 - u_loss: 1.2355 - sub_4_loss: 2.1180e-09 - mul_24_loss: 2.9596e-11\n",
      "Epoch 136/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2300 - u_loss: 1.2300 - sub_4_loss: 2.5015e-09 - mul_24_loss: 3.5251e-11\n",
      "Epoch 137/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2284 - u_loss: 1.2284 - sub_4_loss: 2.5699e-09 - mul_24_loss: 3.6612e-11\n",
      "Epoch 138/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2280 - u_loss: 1.2280 - sub_4_loss: 2.6387e-09 - mul_24_loss: 3.7996e-11\n",
      "Epoch 139/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2285 - u_loss: 1.2285 - sub_4_loss: 2.8840e-09 - mul_24_loss: 4.2097e-11\n",
      "Epoch 140/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2315 - u_loss: 1.2315 - sub_4_loss: 3.3131e-09 - mul_24_loss: 4.8813e-11\n",
      "Epoch 141/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2305 - u_loss: 1.2305 - sub_4_loss: 3.2432e-09 - mul_24_loss: 4.8676e-11\n",
      "Epoch 142/2500\n",
      "10/10 [==============================] - 2s 156ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2295 - u_loss: 1.2295 - sub_4_loss: 3.8520e-09 - mul_24_loss: 5.8236e-11\n",
      "Epoch 143/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2301 - u_loss: 1.2301 - sub_4_loss: 3.9261e-09 - mul_24_loss: 6.0132e-11\n",
      "Epoch 144/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2301 - u_loss: 1.2301 - sub_4_loss: 4.7353e-09 - mul_24_loss: 7.3737e-11\n",
      "Epoch 145/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2294 - u_loss: 1.2294 - sub_4_loss: 4.6106e-09 - mul_24_loss: 7.2799e-11\n",
      "Epoch 146/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2286 - u_loss: 1.2286 - sub_4_loss: 5.6287e-09 - mul_24_loss: 9.0457e-11\n",
      "Epoch 147/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2288 - u_loss: 1.2288 - sub_4_loss: 5.9493e-09 - mul_24_loss: 9.7288e-11\n",
      "Epoch 148/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2294 - u_loss: 1.2294 - sub_4_loss: 6.8685e-09 - mul_24_loss: 1.1329e-10\n",
      "Epoch 149/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2321 - u_loss: 1.2321 - sub_4_loss: 8.9072e-09 - mul_24_loss: 1.5021e-10\n",
      "Epoch 150/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2316 - u_loss: 1.2316 - sub_4_loss: 8.3588e-09 - mul_24_loss: 1.4337e-10\n",
      "Epoch 151/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2343 - u_loss: 1.2343 - sub_4_loss: 1.1439e-08 - mul_24_loss: 2.0038e-10\n",
      "Epoch 152/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2306 - u_loss: 1.2306 - sub_4_loss: 1.1034e-08 - mul_24_loss: 1.9719e-10\n",
      "Epoch 153/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2309 - u_loss: 1.2309 - sub_4_loss: 1.4787e-08 - mul_24_loss: 2.6912e-10\n",
      "Epoch 154/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2279 - u_loss: 1.2279 - sub_4_loss: 1.6646e-08 - mul_24_loss: 3.0929e-10\n",
      "Epoch 155/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2293 - u_loss: 1.2293 - sub_4_loss: 2.2013e-08 - mul_24_loss: 4.2222e-10\n",
      "Epoch 156/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2296 - u_loss: 1.2296 - sub_4_loss: 2.7856e-08 - mul_24_loss: 5.4215e-10\n",
      "Epoch 157/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2305 - u_loss: 1.2304 - sub_4_loss: 4.3757e-08 - mul_24_loss: 8.6934e-10\n",
      "Epoch 158/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2292 - u_loss: 1.2292 - sub_4_loss: 5.7252e-08 - mul_24_loss: 1.1727e-09\n",
      "Epoch 159/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2290 - u_loss: 1.2290 - sub_4_loss: 9.5895e-08 - mul_24_loss: 2.0151e-09\n",
      "Epoch 160/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2293 - u_loss: 1.2293 - sub_4_loss: 1.6606e-07 - mul_24_loss: 3.5853e-09\n",
      "Epoch 161/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2270 - u_loss: 1.2270 - sub_4_loss: 3.6968e-07 - mul_24_loss: 7.9065e-09\n",
      "Epoch 162/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2285 - u_loss: 1.2285 - sub_4_loss: 1.2975e-06 - mul_24_loss: 2.8863e-08\n",
      "Epoch 163/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2335 - u_loss: 1.2335 - sub_4_loss: 6.7845e-06 - mul_24_loss: 1.3533e-07\n",
      "Epoch 164/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.2340 - u_loss: 1.2333 - sub_4_loss: 6.7891e-04 - mul_24_loss: 3.1358e-06\n",
      "Epoch 165/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1110537.6205 - u_loss: 32.7436 - sub_4_loss: 1110504.8750 - mul_24_loss: 7.5596e-05\n",
      "Epoch 166/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 30.8222 - u_loss: 30.8222 - sub_4_loss: 1.9921e-12 - mul_24_loss: 8.9084e-16\n",
      "Epoch 167/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 24.0466 - u_loss: 24.0466 - sub_4_loss: 9.6266e-14 - mul_24_loss: 1.1589e-16\n",
      "Epoch 168/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 22.2670 - u_loss: 22.2670 - sub_4_loss: 4.2699e-13 - mul_24_loss: 4.9980e-16\n",
      "Epoch 169/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 21.4596 - u_loss: 21.4596 - sub_4_loss: 5.4329e-13 - mul_24_loss: 6.1997e-16\n",
      "Epoch 170/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 20.9737 - u_loss: 20.9737 - sub_4_loss: 6.4796e-13 - mul_24_loss: 7.0845e-16\n",
      "Epoch 171/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 20.6140 - u_loss: 20.6140 - sub_4_loss: 6.6637e-13 - mul_24_loss: 7.2403e-16\n",
      "Epoch 172/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 20.3086 - u_loss: 20.3086 - sub_4_loss: 6.6956e-13 - mul_24_loss: 7.2595e-16\n",
      "Epoch 173/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 20.0349 - u_loss: 20.0349 - sub_4_loss: 6.6790e-13 - mul_24_loss: 7.2375e-16\n",
      "Epoch 174/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 19.7756 - u_loss: 19.7756 - sub_4_loss: 6.6436e-13 - mul_24_loss: 7.1982e-16\n",
      "Epoch 175/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 19.5344 - u_loss: 19.5344 - sub_4_loss: 6.6006e-13 - mul_24_loss: 7.1509e-16\n",
      "Epoch 176/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 19.3055 - u_loss: 19.3055 - sub_4_loss: 6.5408e-13 - mul_24_loss: 7.0919e-16\n",
      "Epoch 177/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 19.0861 - u_loss: 19.0861 - sub_4_loss: 6.5088e-13 - mul_24_loss: 7.0546e-16\n",
      "Epoch 178/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 18.8714 - u_loss: 18.8714 - sub_4_loss: 6.4428e-13 - mul_24_loss: 6.9867e-16\n",
      "Epoch 179/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 18.6692 - u_loss: 18.6692 - sub_4_loss: 6.4023e-13 - mul_24_loss: 6.9448e-16\n",
      "Epoch 180/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 18.4720 - u_loss: 18.4720 - sub_4_loss: 6.3610e-13 - mul_24_loss: 6.8979e-16\n",
      "Epoch 181/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 18.2821 - u_loss: 18.2821 - sub_4_loss: 6.3027e-13 - mul_24_loss: 6.8397e-16\n",
      "Epoch 182/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 18.0973 - u_loss: 18.0973 - sub_4_loss: 6.2671e-13 - mul_24_loss: 6.8005e-16\n",
      "Epoch 183/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 17.9165 - u_loss: 17.9165 - sub_4_loss: 6.2220e-13 - mul_24_loss: 6.7542e-16\n",
      "Epoch 184/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 17.7423 - u_loss: 17.7423 - sub_4_loss: 6.1781e-13 - mul_24_loss: 6.7064e-16\n",
      "Epoch 185/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 17.5736 - u_loss: 17.5736 - sub_4_loss: 6.1320e-13 - mul_24_loss: 6.6586e-16\n",
      "Epoch 186/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 17.4079 - u_loss: 17.4079 - sub_4_loss: 6.0988e-13 - mul_24_loss: 6.6219e-16\n",
      "Epoch 187/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 17.2475 - u_loss: 17.2475 - sub_4_loss: 6.0339e-13 - mul_24_loss: 6.5562e-16\n",
      "Epoch 188/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 17.0886 - u_loss: 17.0886 - sub_4_loss: 5.9899e-13 - mul_24_loss: 6.5097e-16\n",
      "Epoch 189/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 16.9349 - u_loss: 16.9349 - sub_4_loss: 5.9348e-13 - mul_24_loss: 6.4525e-16\n",
      "Epoch 190/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 16.7842 - u_loss: 16.7842 - sub_4_loss: 5.9001e-13 - mul_24_loss: 6.4131e-16\n",
      "Epoch 191/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 16.6362 - u_loss: 16.6362 - sub_4_loss: 5.8561e-13 - mul_24_loss: 6.3668e-16\n",
      "Epoch 192/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 16.4930 - u_loss: 16.4930 - sub_4_loss: 5.8122e-13 - mul_24_loss: 6.3214e-16\n",
      "Epoch 193/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 16.3479 - u_loss: 16.3479 - sub_4_loss: 5.7616e-13 - mul_24_loss: 6.2686e-16\n",
      "Epoch 194/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 16.2120 - u_loss: 16.2120 - sub_4_loss: 5.7310e-13 - mul_24_loss: 6.2323e-16\n",
      "Epoch 195/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 16.0733 - u_loss: 16.0733 - sub_4_loss: 5.6784e-13 - mul_24_loss: 6.1795e-16\n",
      "Epoch 196/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 15.9392 - u_loss: 15.9392 - sub_4_loss: 5.6396e-13 - mul_24_loss: 6.1374e-16\n",
      "Epoch 197/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 15.8074 - u_loss: 15.8074 - sub_4_loss: 5.5935e-13 - mul_24_loss: 6.0887e-16\n",
      "Epoch 198/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 15.6795 - u_loss: 15.6795 - sub_4_loss: 5.5409e-13 - mul_24_loss: 6.0352e-16\n",
      "Epoch 199/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 15.5495 - u_loss: 15.5495 - sub_4_loss: 5.4929e-13 - mul_24_loss: 5.9860e-16\n",
      "Epoch 200/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 15.4246 - u_loss: 15.4246 - sub_4_loss: 5.4531e-13 - mul_24_loss: 5.9421e-16\n",
      "Epoch 201/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 15.3011 - u_loss: 15.3011 - sub_4_loss: 5.4131e-13 - mul_24_loss: 5.9011e-16\n",
      "Epoch 202/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 15.1794 - u_loss: 15.1794 - sub_4_loss: 5.3803e-13 - mul_24_loss: 5.8625e-16\n",
      "Epoch 203/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 15.0590 - u_loss: 15.0590 - sub_4_loss: 5.3285e-13 - mul_24_loss: 5.8107e-16\n",
      "Epoch 204/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 14.9402 - u_loss: 14.9402 - sub_4_loss: 5.2935e-13 - mul_24_loss: 5.7713e-16\n",
      "Epoch 205/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 14.8240 - u_loss: 14.8240 - sub_4_loss: 5.2368e-13 - mul_24_loss: 5.7150e-16\n",
      "Epoch 206/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 14.7084 - u_loss: 14.7084 - sub_4_loss: 5.1944e-13 - mul_24_loss: 5.6690e-16\n",
      "Epoch 207/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 14.5961 - u_loss: 14.5961 - sub_4_loss: 5.1615e-13 - mul_24_loss: 5.6316e-16\n",
      "Epoch 208/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 14.4842 - u_loss: 14.4842 - sub_4_loss: 5.1226e-13 - mul_24_loss: 5.5903e-16\n",
      "Epoch 209/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 14.3720 - u_loss: 14.3720 - sub_4_loss: 5.0629e-13 - mul_24_loss: 5.5298e-16\n",
      "Epoch 210/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 14.2640 - u_loss: 14.2640 - sub_4_loss: 5.0505e-13 - mul_24_loss: 5.5133e-16\n",
      "Epoch 211/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 14.1555 - u_loss: 14.1555 - sub_4_loss: 5.0025e-13 - mul_24_loss: 5.4625e-16\n",
      "Epoch 212/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 14.0497 - u_loss: 14.0497 - sub_4_loss: 4.9607e-13 - mul_24_loss: 5.4182e-16\n",
      "Epoch 213/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 13.9439 - u_loss: 13.9439 - sub_4_loss: 4.9098e-13 - mul_24_loss: 5.3643e-16\n",
      "Epoch 214/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 13.8407 - u_loss: 13.8407 - sub_4_loss: 4.8841e-13 - mul_24_loss: 5.3368e-16\n",
      "Epoch 215/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 13.7382 - u_loss: 13.7382 - sub_4_loss: 4.8206e-13 - mul_24_loss: 5.2718e-16\n",
      "Epoch 216/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 13.6362 - u_loss: 13.6362 - sub_4_loss: 4.7940e-13 - mul_24_loss: 5.2413e-16\n",
      "Epoch 217/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 13.5362 - u_loss: 13.5362 - sub_4_loss: 4.7561e-13 - mul_24_loss: 5.1997e-16\n",
      "Epoch 218/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 13.4372 - u_loss: 13.4372 - sub_4_loss: 4.7177e-13 - mul_24_loss: 5.1596e-16\n",
      "Epoch 219/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 13.3379 - u_loss: 13.3379 - sub_4_loss: 4.6777e-13 - mul_24_loss: 5.1172e-16\n",
      "Epoch 220/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 13.2415 - u_loss: 13.2415 - sub_4_loss: 4.6294e-13 - mul_24_loss: 5.0652e-16\n",
      "Epoch 221/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 13.1444 - u_loss: 13.1444 - sub_4_loss: 4.5896e-13 - mul_24_loss: 5.0251e-16\n",
      "Epoch 222/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 13.0509 - u_loss: 13.0509 - sub_4_loss: 4.5429e-13 - mul_24_loss: 4.9773e-16\n",
      "Epoch 223/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 12.9557 - u_loss: 12.9557 - sub_4_loss: 4.5025e-13 - mul_24_loss: 4.9327e-16\n",
      "Epoch 224/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 12.8628 - u_loss: 12.8628 - sub_4_loss: 4.4712e-13 - mul_24_loss: 4.8990e-16\n",
      "Epoch 225/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 12.7698 - u_loss: 12.7698 - sub_4_loss: 4.4228e-13 - mul_24_loss: 4.8495e-16\n",
      "Epoch 226/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 12.6783 - u_loss: 12.6783 - sub_4_loss: 4.3820e-13 - mul_24_loss: 4.8076e-16\n",
      "Epoch 227/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 12.5891 - u_loss: 12.5891 - sub_4_loss: 4.3596e-13 - mul_24_loss: 4.7806e-16\n",
      "Epoch 228/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 12.4984 - u_loss: 12.4984 - sub_4_loss: 4.3119e-13 - mul_24_loss: 4.7299e-16\n",
      "Epoch 229/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 12.4111 - u_loss: 12.4111 - sub_4_loss: 4.2640e-13 - mul_24_loss: 4.6810e-16\n",
      "Epoch 230/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 12.3224 - u_loss: 12.3224 - sub_4_loss: 4.2377e-13 - mul_24_loss: 4.6523e-16\n",
      "Epoch 231/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 12.2354 - u_loss: 12.2354 - sub_4_loss: 4.2006e-13 - mul_24_loss: 4.6120e-16\n",
      "Epoch 232/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 12.1486 - u_loss: 12.1486 - sub_4_loss: 4.1561e-13 - mul_24_loss: 4.5653e-16\n",
      "Epoch 233/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 12.0633 - u_loss: 12.0633 - sub_4_loss: 4.1199e-13 - mul_24_loss: 4.5254e-16\n",
      "Epoch 234/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.9788 - u_loss: 11.9788 - sub_4_loss: 4.0847e-13 - mul_24_loss: 4.4892e-16\n",
      "Epoch 235/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.8947 - u_loss: 11.8947 - sub_4_loss: 4.0487e-13 - mul_24_loss: 4.4499e-16\n",
      "Epoch 236/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.8117 - u_loss: 11.8117 - sub_4_loss: 4.0120e-13 - mul_24_loss: 4.4109e-16\n",
      "Epoch 237/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.7298 - u_loss: 11.7298 - sub_4_loss: 3.9751e-13 - mul_24_loss: 4.3719e-16\n",
      "Epoch 238/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.6478 - u_loss: 11.6478 - sub_4_loss: 3.9358e-13 - mul_24_loss: 4.3298e-16\n",
      "Epoch 239/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.5667 - u_loss: 11.5667 - sub_4_loss: 3.8962e-13 - mul_24_loss: 4.2859e-16\n",
      "Epoch 240/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.4853 - u_loss: 11.4853 - sub_4_loss: 3.8533e-13 - mul_24_loss: 4.2443e-16\n",
      "Epoch 241/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.4062 - u_loss: 11.4062 - sub_4_loss: 3.8124e-13 - mul_24_loss: 4.2006e-16\n",
      "Epoch 242/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.3274 - u_loss: 11.3273 - sub_4_loss: 3.7753e-13 - mul_24_loss: 4.1612e-16\n",
      "Epoch 243/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.2487 - u_loss: 11.2487 - sub_4_loss: 3.7418e-13 - mul_24_loss: 4.1240e-16\n",
      "Epoch 244/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.1715 - u_loss: 11.1715 - sub_4_loss: 3.7097e-13 - mul_24_loss: 4.0895e-16\n",
      "Epoch 245/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.0939 - u_loss: 11.0939 - sub_4_loss: 3.6680e-13 - mul_24_loss: 4.0461e-16\n",
      "Epoch 246/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 11.0182 - u_loss: 11.0182 - sub_4_loss: 3.6386e-13 - mul_24_loss: 4.0141e-16\n",
      "Epoch 247/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.9414 - u_loss: 10.9414 - sub_4_loss: 3.5993e-13 - mul_24_loss: 3.9715e-16\n",
      "Epoch 248/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.8668 - u_loss: 10.8668 - sub_4_loss: 3.5799e-13 - mul_24_loss: 3.9502e-16\n",
      "Epoch 249/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.7922 - u_loss: 10.7922 - sub_4_loss: 3.5219e-13 - mul_24_loss: 3.8911e-16\n",
      "Epoch 250/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.7180 - u_loss: 10.7180 - sub_4_loss: 3.5057e-13 - mul_24_loss: 3.8700e-16\n",
      "Epoch 251/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.6435 - u_loss: 10.6435 - sub_4_loss: 3.4551e-13 - mul_24_loss: 3.8199e-16\n",
      "Epoch 252/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.5717 - u_loss: 10.5717 - sub_4_loss: 3.4295e-13 - mul_24_loss: 3.7898e-16\n",
      "Epoch 253/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.4987 - u_loss: 10.4987 - sub_4_loss: 3.3912e-13 - mul_24_loss: 3.7504e-16\n",
      "Epoch 254/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.4279 - u_loss: 10.4279 - sub_4_loss: 3.3671e-13 - mul_24_loss: 3.7236e-16\n",
      "Epoch 255/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.3563 - u_loss: 10.3563 - sub_4_loss: 3.3324e-13 - mul_24_loss: 3.6880e-16\n",
      "Epoch 256/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.2845 - u_loss: 10.2845 - sub_4_loss: 3.2943e-13 - mul_24_loss: 3.6463e-16\n",
      "Epoch 257/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.2151 - u_loss: 10.2151 - sub_4_loss: 3.2502e-13 - mul_24_loss: 3.6009e-16\n",
      "Epoch 258/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.1461 - u_loss: 10.1461 - sub_4_loss: 3.2335e-13 - mul_24_loss: 3.5799e-16\n",
      "Epoch 259/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.0766 - u_loss: 10.0766 - sub_4_loss: 3.1970e-13 - mul_24_loss: 3.5414e-16\n",
      "Epoch 260/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 10.0070 - u_loss: 10.0070 - sub_4_loss: 3.1647e-13 - mul_24_loss: 3.5065e-16\n",
      "Epoch 261/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.9397 - u_loss: 9.9397 - sub_4_loss: 3.1186e-13 - mul_24_loss: 3.4611e-16\n",
      "Epoch 262/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.8715 - u_loss: 9.8715 - sub_4_loss: 3.0973e-13 - mul_24_loss: 3.4378e-16\n",
      "Epoch 263/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.8054 - u_loss: 9.8054 - sub_4_loss: 3.0531e-13 - mul_24_loss: 3.3913e-16\n",
      "Epoch 264/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.7388 - u_loss: 9.7388 - sub_4_loss: 3.0374e-13 - mul_24_loss: 3.3706e-16\n",
      "Epoch 265/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.6710 - u_loss: 9.6710 - sub_4_loss: 2.9878e-13 - mul_24_loss: 3.3210e-16\n",
      "Epoch 266/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.6069 - u_loss: 9.6069 - sub_4_loss: 2.9523e-13 - mul_24_loss: 3.2817e-16\n",
      "Epoch 267/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.5408 - u_loss: 9.5408 - sub_4_loss: 2.9275e-13 - mul_24_loss: 3.2547e-16\n",
      "Epoch 268/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.4766 - u_loss: 9.4766 - sub_4_loss: 2.8974e-13 - mul_24_loss: 3.2244e-16\n",
      "Epoch 269/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.4124 - u_loss: 9.4124 - sub_4_loss: 2.8772e-13 - mul_24_loss: 3.1999e-16\n",
      "Epoch 270/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.3478 - u_loss: 9.3478 - sub_4_loss: 2.8451e-13 - mul_24_loss: 3.1660e-16\n",
      "Epoch 271/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.2853 - u_loss: 9.2853 - sub_4_loss: 2.8164e-13 - mul_24_loss: 3.1341e-16\n",
      "Epoch 272/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.2217 - u_loss: 9.2217 - sub_4_loss: 2.7740e-13 - mul_24_loss: 3.0908e-16\n",
      "Epoch 273/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.1596 - u_loss: 9.1596 - sub_4_loss: 2.7411e-13 - mul_24_loss: 3.0568e-16\n",
      "Epoch 274/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.0978 - u_loss: 9.0978 - sub_4_loss: 2.7111e-13 - mul_24_loss: 3.0231e-16\n",
      "Epoch 275/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 9.0358 - u_loss: 9.0358 - sub_4_loss: 2.6946e-13 - mul_24_loss: 3.0037e-16\n",
      "Epoch 276/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.9743 - u_loss: 8.9743 - sub_4_loss: 2.6662e-13 - mul_24_loss: 2.9739e-16\n",
      "Epoch 277/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.9138 - u_loss: 8.9138 - sub_4_loss: 2.6351e-13 - mul_24_loss: 2.9403e-16\n",
      "Epoch 278/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.8538 - u_loss: 8.8538 - sub_4_loss: 2.5891e-13 - mul_24_loss: 2.8932e-16\n",
      "Epoch 279/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.7932 - u_loss: 8.7932 - sub_4_loss: 2.5638e-13 - mul_24_loss: 2.8665e-16\n",
      "Epoch 280/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.7342 - u_loss: 8.7342 - sub_4_loss: 2.5357e-13 - mul_24_loss: 2.8369e-16\n",
      "Epoch 281/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.6747 - u_loss: 8.6747 - sub_4_loss: 2.5045e-13 - mul_24_loss: 2.8029e-16\n",
      "Epoch 282/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.6161 - u_loss: 8.6161 - sub_4_loss: 2.4844e-13 - mul_24_loss: 2.7796e-16\n",
      "Epoch 283/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.5575 - u_loss: 8.5575 - sub_4_loss: 2.4536e-13 - mul_24_loss: 2.7460e-16\n",
      "Epoch 284/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.5003 - u_loss: 8.5003 - sub_4_loss: 2.4150e-13 - mul_24_loss: 2.7068e-16\n",
      "Epoch 285/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.4422 - u_loss: 8.4422 - sub_4_loss: 2.4036e-13 - mul_24_loss: 2.6925e-16\n",
      "Epoch 286/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.3853 - u_loss: 8.3853 - sub_4_loss: 2.3636e-13 - mul_24_loss: 2.6511e-16\n",
      "Epoch 287/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.3283 - u_loss: 8.3283 - sub_4_loss: 2.3508e-13 - mul_24_loss: 2.6356e-16\n",
      "Epoch 288/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.2725 - u_loss: 8.2725 - sub_4_loss: 2.3157e-13 - mul_24_loss: 2.5992e-16\n",
      "Epoch 289/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.2157 - u_loss: 8.2157 - sub_4_loss: 2.2849e-13 - mul_24_loss: 2.5681e-16\n",
      "Epoch 290/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.1604 - u_loss: 8.1604 - sub_4_loss: 2.2607e-13 - mul_24_loss: 2.5398e-16\n",
      "Epoch 291/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.1052 - u_loss: 8.1052 - sub_4_loss: 2.2401e-13 - mul_24_loss: 2.5170e-16\n",
      "Epoch 292/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 8.0500 - u_loss: 8.0500 - sub_4_loss: 2.2122e-13 - mul_24_loss: 2.4874e-16\n",
      "Epoch 293/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.9962 - u_loss: 7.9962 - sub_4_loss: 2.1781e-13 - mul_24_loss: 2.4521e-16\n",
      "Epoch 294/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.9416 - u_loss: 7.9416 - sub_4_loss: 2.1596e-13 - mul_24_loss: 2.4307e-16\n",
      "Epoch 295/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.8875 - u_loss: 7.8875 - sub_4_loss: 2.1338e-13 - mul_24_loss: 2.4030e-16\n",
      "Epoch 296/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.8352 - u_loss: 7.8352 - sub_4_loss: 2.0995e-13 - mul_24_loss: 2.3683e-16\n",
      "Epoch 297/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.7812 - u_loss: 7.7812 - sub_4_loss: 2.0710e-13 - mul_24_loss: 2.3384e-16\n",
      "Epoch 298/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.7287 - u_loss: 7.7287 - sub_4_loss: 2.0529e-13 - mul_24_loss: 2.3173e-16\n",
      "Epoch 299/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.6758 - u_loss: 7.6758 - sub_4_loss: 2.0218e-13 - mul_24_loss: 2.2836e-16\n",
      "Epoch 300/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.6240 - u_loss: 7.6240 - sub_4_loss: 2.0086e-13 - mul_24_loss: 2.2684e-16\n",
      "Epoch 301/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.5723 - u_loss: 7.5723 - sub_4_loss: 1.9805e-13 - mul_24_loss: 2.2379e-16\n",
      "Epoch 302/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.5217 - u_loss: 7.5217 - sub_4_loss: 1.9566e-13 - mul_24_loss: 2.2127e-16\n",
      "Epoch 303/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.4700 - u_loss: 7.4700 - sub_4_loss: 1.9261e-13 - mul_24_loss: 2.1813e-16\n",
      "Epoch 304/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.4195 - u_loss: 7.4195 - sub_4_loss: 1.9073e-13 - mul_24_loss: 2.1602e-16\n",
      "Epoch 305/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.3690 - u_loss: 7.3690 - sub_4_loss: 1.8818e-13 - mul_24_loss: 2.1328e-16\n",
      "Epoch 306/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.3193 - u_loss: 7.3193 - sub_4_loss: 1.8511e-13 - mul_24_loss: 2.1004e-16\n",
      "Epoch 307/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.2690 - u_loss: 7.2690 - sub_4_loss: 1.8349e-13 - mul_24_loss: 2.0818e-16\n",
      "Epoch 308/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.2204 - u_loss: 7.2204 - sub_4_loss: 1.8082e-13 - mul_24_loss: 2.0541e-16\n",
      "Epoch 309/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.1710 - u_loss: 7.1710 - sub_4_loss: 1.7805e-13 - mul_24_loss: 2.0249e-16\n",
      "Epoch 310/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.1224 - u_loss: 7.1224 - sub_4_loss: 1.7694e-13 - mul_24_loss: 2.0110e-16\n",
      "Epoch 311/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.0744 - u_loss: 7.0744 - sub_4_loss: 1.7476e-13 - mul_24_loss: 1.9871e-16\n",
      "Epoch 312/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 7.0258 - u_loss: 7.0258 - sub_4_loss: 1.7119e-13 - mul_24_loss: 1.9508e-16\n",
      "Epoch 313/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.9775 - u_loss: 6.9775 - sub_4_loss: 1.6990e-13 - mul_24_loss: 1.9350e-16\n",
      "Epoch 314/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.9309 - u_loss: 6.9309 - sub_4_loss: 1.6711e-13 - mul_24_loss: 1.9073e-16\n",
      "Epoch 315/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.8834 - u_loss: 6.8834 - sub_4_loss: 1.6537e-13 - mul_24_loss: 1.8866e-16\n",
      "Epoch 316/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.8371 - u_loss: 6.8371 - sub_4_loss: 1.6241e-13 - mul_24_loss: 1.8558e-16\n",
      "Epoch 317/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.7898 - u_loss: 6.7898 - sub_4_loss: 1.6153e-13 - mul_24_loss: 1.8448e-16\n",
      "Epoch 318/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.7439 - u_loss: 6.7439 - sub_4_loss: 1.5892e-13 - mul_24_loss: 1.8170e-16\n",
      "Epoch 319/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.6986 - u_loss: 6.6986 - sub_4_loss: 1.5730e-13 - mul_24_loss: 1.7990e-16\n",
      "Epoch 320/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.6521 - u_loss: 6.6521 - sub_4_loss: 1.5521e-13 - mul_24_loss: 1.7760e-16\n",
      "Epoch 321/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.6078 - u_loss: 6.6078 - sub_4_loss: 1.5231e-13 - mul_24_loss: 1.7469e-16\n",
      "Epoch 322/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.5624 - u_loss: 6.5624 - sub_4_loss: 1.5035e-13 - mul_24_loss: 1.7250e-16\n",
      "Epoch 323/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.5171 - u_loss: 6.5171 - sub_4_loss: 1.4901e-13 - mul_24_loss: 1.7099e-16\n",
      "Epoch 324/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.4734 - u_loss: 6.4734 - sub_4_loss: 1.4652e-13 - mul_24_loss: 1.6838e-16\n",
      "Epoch 325/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.4290 - u_loss: 6.4290 - sub_4_loss: 1.4492e-13 - mul_24_loss: 1.6652e-16\n",
      "Epoch 326/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.3848 - u_loss: 6.3848 - sub_4_loss: 1.4301e-13 - mul_24_loss: 1.6436e-16\n",
      "Epoch 327/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.3417 - u_loss: 6.3417 - sub_4_loss: 1.4046e-13 - mul_24_loss: 1.6173e-16\n",
      "Epoch 328/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.2981 - u_loss: 6.2981 - sub_4_loss: 1.3900e-13 - mul_24_loss: 1.6017e-16\n",
      "Epoch 329/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.2556 - u_loss: 6.2556 - sub_4_loss: 1.3653e-13 - mul_24_loss: 1.5762e-16\n",
      "Epoch 330/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.2128 - u_loss: 6.2128 - sub_4_loss: 1.3520e-13 - mul_24_loss: 1.5600e-16\n",
      "Epoch 331/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.1705 - u_loss: 6.1705 - sub_4_loss: 1.3320e-13 - mul_24_loss: 1.5391e-16\n",
      "Epoch 332/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.1277 - u_loss: 6.1277 - sub_4_loss: 1.3125e-13 - mul_24_loss: 1.5181e-16\n",
      "Epoch 333/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.0861 - u_loss: 6.0861 - sub_4_loss: 1.2983e-13 - mul_24_loss: 1.5010e-16\n",
      "Epoch 334/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.0449 - u_loss: 6.0449 - sub_4_loss: 1.2795e-13 - mul_24_loss: 1.4816e-16\n",
      "Epoch 335/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 6.0031 - u_loss: 6.0031 - sub_4_loss: 1.2561e-13 - mul_24_loss: 1.4572e-16\n",
      "Epoch 336/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.9624 - u_loss: 5.9624 - sub_4_loss: 1.2403e-13 - mul_24_loss: 1.4392e-16\n",
      "Epoch 337/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.9215 - u_loss: 5.9215 - sub_4_loss: 1.2204e-13 - mul_24_loss: 1.4186e-16\n",
      "Epoch 338/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.8814 - u_loss: 5.8814 - sub_4_loss: 1.2060e-13 - mul_24_loss: 1.4026e-16\n",
      "Epoch 339/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.8405 - u_loss: 5.8405 - sub_4_loss: 1.1859e-13 - mul_24_loss: 1.3806e-16\n",
      "Epoch 340/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.8007 - u_loss: 5.8007 - sub_4_loss: 1.1706e-13 - mul_24_loss: 1.3640e-16\n",
      "Epoch 341/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.7612 - u_loss: 5.7612 - sub_4_loss: 1.1528e-13 - mul_24_loss: 1.3448e-16\n",
      "Epoch 342/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.7215 - u_loss: 5.7215 - sub_4_loss: 1.1359e-13 - mul_24_loss: 1.3265e-16\n",
      "Epoch 343/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.6825 - u_loss: 5.6825 - sub_4_loss: 1.1253e-13 - mul_24_loss: 1.3133e-16\n",
      "Epoch 344/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.6435 - u_loss: 5.6435 - sub_4_loss: 1.1117e-13 - mul_24_loss: 1.2983e-16\n",
      "Epoch 345/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.6049 - u_loss: 5.6049 - sub_4_loss: 1.0929e-13 - mul_24_loss: 1.2785e-16\n",
      "Epoch 346/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.5665 - u_loss: 5.5665 - sub_4_loss: 1.0744e-13 - mul_24_loss: 1.2584e-16\n",
      "Epoch 347/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.5285 - u_loss: 5.5285 - sub_4_loss: 1.0605e-13 - mul_24_loss: 1.2423e-16\n",
      "Epoch 348/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.4908 - u_loss: 5.4908 - sub_4_loss: 1.0444e-13 - mul_24_loss: 1.2259e-16\n",
      "Epoch 349/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.4528 - u_loss: 5.4528 - sub_4_loss: 1.0317e-13 - mul_24_loss: 1.2113e-16\n",
      "Epoch 350/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.4152 - u_loss: 5.4152 - sub_4_loss: 1.0096e-13 - mul_24_loss: 1.1883e-16\n",
      "Epoch 351/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.3783 - u_loss: 5.3783 - sub_4_loss: 9.9602e-14 - mul_24_loss: 1.1739e-16\n",
      "Epoch 352/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.3415 - u_loss: 5.3415 - sub_4_loss: 9.8876e-14 - mul_24_loss: 1.1645e-16\n",
      "Epoch 353/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.3049 - u_loss: 5.3049 - sub_4_loss: 9.7323e-14 - mul_24_loss: 1.1472e-16\n",
      "Epoch 354/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.2683 - u_loss: 5.2683 - sub_4_loss: 9.5712e-14 - mul_24_loss: 1.1296e-16\n",
      "Epoch 355/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.2323 - u_loss: 5.2323 - sub_4_loss: 9.4127e-14 - mul_24_loss: 1.1128e-16\n",
      "Epoch 356/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.1961 - u_loss: 5.1961 - sub_4_loss: 9.2451e-14 - mul_24_loss: 1.0949e-16\n",
      "Epoch 357/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.1606 - u_loss: 5.1606 - sub_4_loss: 9.1114e-14 - mul_24_loss: 1.0800e-16\n",
      "Epoch 358/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.1254 - u_loss: 5.1254 - sub_4_loss: 8.9999e-14 - mul_24_loss: 1.0676e-16\n",
      "Epoch 359/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.0901 - u_loss: 5.0901 - sub_4_loss: 8.8826e-14 - mul_24_loss: 1.0539e-16\n",
      "Epoch 360/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.0548 - u_loss: 5.0548 - sub_4_loss: 8.7504e-14 - mul_24_loss: 1.0395e-16\n",
      "Epoch 361/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 5.0203 - u_loss: 5.0203 - sub_4_loss: 8.6093e-14 - mul_24_loss: 1.0244e-16\n",
      "Epoch 362/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.9860 - u_loss: 4.9860 - sub_4_loss: 8.4689e-14 - mul_24_loss: 1.0090e-16\n",
      "Epoch 363/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.9517 - u_loss: 4.9517 - sub_4_loss: 8.3328e-14 - mul_24_loss: 9.9423e-17\n",
      "Epoch 364/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.9172 - u_loss: 4.9172 - sub_4_loss: 8.1772e-14 - mul_24_loss: 9.7739e-17\n",
      "Epoch 365/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.8837 - u_loss: 4.8837 - sub_4_loss: 8.0871e-14 - mul_24_loss: 9.6660e-17\n",
      "Epoch 366/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.8503 - u_loss: 4.8503 - sub_4_loss: 7.9487e-14 - mul_24_loss: 9.5197e-17\n",
      "Epoch 367/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.8167 - u_loss: 4.8167 - sub_4_loss: 7.8571e-14 - mul_24_loss: 9.4132e-17\n",
      "Epoch 368/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.7837 - u_loss: 4.7837 - sub_4_loss: 7.7348e-14 - mul_24_loss: 9.2765e-17\n",
      "Epoch 369/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.7506 - u_loss: 4.7506 - sub_4_loss: 7.5562e-14 - mul_24_loss: 9.0895e-17\n",
      "Epoch 370/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.7182 - u_loss: 4.7182 - sub_4_loss: 7.4369e-14 - mul_24_loss: 8.9586e-17\n",
      "Epoch 371/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.6860 - u_loss: 4.6860 - sub_4_loss: 7.3797e-14 - mul_24_loss: 8.8858e-17\n",
      "Epoch 372/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.6536 - u_loss: 4.6536 - sub_4_loss: 7.2190e-14 - mul_24_loss: 8.7111e-17\n",
      "Epoch 373/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.6217 - u_loss: 4.6217 - sub_4_loss: 7.0991e-14 - mul_24_loss: 8.5791e-17\n",
      "Epoch 374/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.5898 - u_loss: 4.5898 - sub_4_loss: 7.0200e-14 - mul_24_loss: 8.4909e-17\n",
      "Epoch 375/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.5582 - u_loss: 4.5582 - sub_4_loss: 6.8961e-14 - mul_24_loss: 8.3505e-17\n",
      "Epoch 376/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.5269 - u_loss: 4.5269 - sub_4_loss: 6.7728e-14 - mul_24_loss: 8.2169e-17\n",
      "Epoch 377/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.4959 - u_loss: 4.4959 - sub_4_loss: 6.6719e-14 - mul_24_loss: 8.1035e-17\n",
      "Epoch 378/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.4645 - u_loss: 4.4645 - sub_4_loss: 6.5659e-14 - mul_24_loss: 7.9853e-17\n",
      "Epoch 379/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.4341 - u_loss: 4.4341 - sub_4_loss: 6.4873e-14 - mul_24_loss: 7.8963e-17\n",
      "Epoch 380/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.4034 - u_loss: 4.4034 - sub_4_loss: 6.3891e-14 - mul_24_loss: 7.7836e-17\n",
      "Epoch 381/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.3735 - u_loss: 4.3735 - sub_4_loss: 6.2765e-14 - mul_24_loss: 7.6614e-17\n",
      "Epoch 382/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.3439 - u_loss: 4.3439 - sub_4_loss: 6.1771e-14 - mul_24_loss: 7.5475e-17\n",
      "Epoch 383/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.3135 - u_loss: 4.3135 - sub_4_loss: 6.0899e-14 - mul_24_loss: 7.4506e-17\n",
      "Epoch 384/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.2836 - u_loss: 4.2836 - sub_4_loss: 5.9742e-14 - mul_24_loss: 7.3231e-17\n",
      "Epoch 385/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.2547 - u_loss: 4.2547 - sub_4_loss: 5.8851e-14 - mul_24_loss: 7.2239e-17\n",
      "Epoch 386/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.2253 - u_loss: 4.2253 - sub_4_loss: 5.7961e-14 - mul_24_loss: 7.1222e-17\n",
      "Epoch 387/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.1960 - u_loss: 4.1960 - sub_4_loss: 5.7073e-14 - mul_24_loss: 7.0243e-17\n",
      "Epoch 388/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.1674 - u_loss: 4.1674 - sub_4_loss: 5.5906e-14 - mul_24_loss: 6.8952e-17\n",
      "Epoch 389/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.1389 - u_loss: 4.1389 - sub_4_loss: 5.4864e-14 - mul_24_loss: 6.7807e-17\n",
      "Epoch 390/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.1106 - u_loss: 4.1106 - sub_4_loss: 5.3891e-14 - mul_24_loss: 6.6728e-17\n",
      "Epoch 391/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.0823 - u_loss: 4.0823 - sub_4_loss: 5.3412e-14 - mul_24_loss: 6.6109e-17\n",
      "Epoch 392/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.0543 - u_loss: 4.0543 - sub_4_loss: 5.2302e-14 - mul_24_loss: 6.4910e-17\n",
      "Epoch 393/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 4.0262 - u_loss: 4.0262 - sub_4_loss: 5.1489e-14 - mul_24_loss: 6.4002e-17\n",
      "Epoch 394/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.9990 - u_loss: 3.9990 - sub_4_loss: 5.0370e-14 - mul_24_loss: 6.2768e-17\n",
      "Epoch 395/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.9712 - u_loss: 3.9712 - sub_4_loss: 4.9573e-14 - mul_24_loss: 6.1868e-17\n",
      "Epoch 396/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.9444 - u_loss: 3.9444 - sub_4_loss: 4.8702e-14 - mul_24_loss: 6.0860e-17\n",
      "Epoch 397/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.9174 - u_loss: 3.9174 - sub_4_loss: 4.7824e-14 - mul_24_loss: 5.9905e-17\n",
      "Epoch 398/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.8902 - u_loss: 3.8902 - sub_4_loss: 4.7534e-14 - mul_24_loss: 5.9529e-17\n",
      "Epoch 399/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.8641 - u_loss: 3.8641 - sub_4_loss: 4.6244e-14 - mul_24_loss: 5.8107e-17\n",
      "Epoch 400/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.8371 - u_loss: 3.8371 - sub_4_loss: 4.5401e-14 - mul_24_loss: 5.7151e-17\n",
      "Epoch 401/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.8109 - u_loss: 3.8109 - sub_4_loss: 4.4778e-14 - mul_24_loss: 5.6459e-17\n",
      "Epoch 402/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.7853 - u_loss: 3.7853 - sub_4_loss: 4.4259e-14 - mul_24_loss: 5.5790e-17\n",
      "Epoch 403/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.7590 - u_loss: 3.7590 - sub_4_loss: 4.3456e-14 - mul_24_loss: 5.4896e-17\n",
      "Epoch 404/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.7336 - u_loss: 3.7336 - sub_4_loss: 4.2719e-14 - mul_24_loss: 5.4096e-17\n",
      "Epoch 405/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.7081 - u_loss: 3.7081 - sub_4_loss: 4.2012e-14 - mul_24_loss: 5.3267e-17\n",
      "Epoch 406/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.6829 - u_loss: 3.6829 - sub_4_loss: 4.1297e-14 - mul_24_loss: 5.2443e-17\n",
      "Epoch 407/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.6578 - u_loss: 3.6578 - sub_4_loss: 4.0585e-14 - mul_24_loss: 5.1637e-17\n",
      "Epoch 408/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.6327 - u_loss: 3.6327 - sub_4_loss: 3.9921e-14 - mul_24_loss: 5.0862e-17\n",
      "Epoch 409/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.6082 - u_loss: 3.6082 - sub_4_loss: 3.9138e-14 - mul_24_loss: 4.9989e-17\n",
      "Epoch 410/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.5831 - u_loss: 3.5831 - sub_4_loss: 3.8366e-14 - mul_24_loss: 4.9146e-17\n",
      "Epoch 411/2500\n",
      "10/10 [==============================] - ETA: 0s - batch: 4.5000 - size: 5000.0000 - loss: 3.5590 - u_loss: 3.5590 - sub_4_loss: 3.7709e-14 - mul_24_loss: 4.8375e-17\n",
      "Epoch 00411: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.5590 - u_loss: 3.5590 - sub_4_loss: 3.7709e-14 - mul_24_loss: 4.8375e-17\n",
      "Epoch 412/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.5404 - u_loss: 3.5404 - sub_4_loss: 3.7215e-14 - mul_24_loss: 4.7822e-17\n",
      "Epoch 413/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.5284 - u_loss: 3.5284 - sub_4_loss: 3.6867e-14 - mul_24_loss: 4.7418e-17\n",
      "Epoch 414/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.5164 - u_loss: 3.5164 - sub_4_loss: 3.6615e-14 - mul_24_loss: 4.7115e-17\n",
      "Epoch 415/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.5042 - u_loss: 3.5042 - sub_4_loss: 3.6213e-14 - mul_24_loss: 4.6672e-17\n",
      "Epoch 416/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.4925 - u_loss: 3.4925 - sub_4_loss: 3.6003e-14 - mul_24_loss: 4.6403e-17\n",
      "Epoch 417/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.4804 - u_loss: 3.4804 - sub_4_loss: 3.5644e-14 - mul_24_loss: 4.5999e-17\n",
      "Epoch 418/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.4686 - u_loss: 3.4686 - sub_4_loss: 3.5307e-14 - mul_24_loss: 4.5618e-17\n",
      "Epoch 419/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.4568 - u_loss: 3.4568 - sub_4_loss: 3.4931e-14 - mul_24_loss: 4.5189e-17\n",
      "Epoch 420/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.4447 - u_loss: 3.4447 - sub_4_loss: 3.4732e-14 - mul_24_loss: 4.4955e-17\n",
      "Epoch 421/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.4331 - u_loss: 3.4331 - sub_4_loss: 3.4332e-14 - mul_24_loss: 4.4505e-17\n",
      "Epoch 422/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.4213 - u_loss: 3.4213 - sub_4_loss: 3.4105e-14 - mul_24_loss: 4.4233e-17\n",
      "Epoch 423/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.4094 - u_loss: 3.4094 - sub_4_loss: 3.3728e-14 - mul_24_loss: 4.3810e-17\n",
      "Epoch 424/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.3977 - u_loss: 3.3977 - sub_4_loss: 3.3452e-14 - mul_24_loss: 4.3489e-17\n",
      "Epoch 425/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.3861 - u_loss: 3.3861 - sub_4_loss: 3.3079e-14 - mul_24_loss: 4.3064e-17\n",
      "Epoch 426/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.3744 - u_loss: 3.3744 - sub_4_loss: 3.2796e-14 - mul_24_loss: 4.2746e-17\n",
      "Epoch 427/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.3627 - u_loss: 3.3627 - sub_4_loss: 3.2549e-14 - mul_24_loss: 4.2447e-17\n",
      "Epoch 428/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.3512 - u_loss: 3.3512 - sub_4_loss: 3.2222e-14 - mul_24_loss: 4.2075e-17\n",
      "Epoch 429/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.3396 - u_loss: 3.3396 - sub_4_loss: 3.1873e-14 - mul_24_loss: 4.1675e-17\n",
      "Epoch 430/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.3279 - u_loss: 3.3279 - sub_4_loss: 3.1606e-14 - mul_24_loss: 4.1350e-17\n",
      "Epoch 431/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.3164 - u_loss: 3.3164 - sub_4_loss: 3.1335e-14 - mul_24_loss: 4.1058e-17\n",
      "Epoch 432/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.3048 - u_loss: 3.3048 - sub_4_loss: 3.0998e-14 - mul_24_loss: 4.0673e-17\n",
      "Epoch 433/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.2934 - u_loss: 3.2934 - sub_4_loss: 3.0663e-14 - mul_24_loss: 4.0280e-17\n",
      "Epoch 434/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.2820 - u_loss: 3.2819 - sub_4_loss: 3.0428e-14 - mul_24_loss: 4.0002e-17\n",
      "Epoch 435/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.2705 - u_loss: 3.2705 - sub_4_loss: 3.0160e-14 - mul_24_loss: 3.9691e-17\n",
      "Epoch 436/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.2591 - u_loss: 3.2591 - sub_4_loss: 2.9935e-14 - mul_24_loss: 3.9415e-17\n",
      "Epoch 437/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.2478 - u_loss: 3.2478 - sub_4_loss: 2.9598e-14 - mul_24_loss: 3.9025e-17\n",
      "Epoch 438/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.2365 - u_loss: 3.2365 - sub_4_loss: 2.9323e-14 - mul_24_loss: 3.8710e-17\n",
      "Epoch 439/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.2252 - u_loss: 3.2252 - sub_4_loss: 2.9008e-14 - mul_24_loss: 3.8354e-17\n",
      "Epoch 440/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.2140 - u_loss: 3.2140 - sub_4_loss: 2.8715e-14 - mul_24_loss: 3.8019e-17\n",
      "Epoch 441/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.2026 - u_loss: 3.2026 - sub_4_loss: 2.8450e-14 - mul_24_loss: 3.7705e-17\n",
      "Epoch 442/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.1915 - u_loss: 3.1915 - sub_4_loss: 2.8205e-14 - mul_24_loss: 3.7422e-17\n",
      "Epoch 443/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.1803 - u_loss: 3.1803 - sub_4_loss: 2.7965e-14 - mul_24_loss: 3.7126e-17\n",
      "Epoch 444/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.1691 - u_loss: 3.1691 - sub_4_loss: 2.7687e-14 - mul_24_loss: 3.6819e-17\n",
      "Epoch 445/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.1580 - u_loss: 3.1580 - sub_4_loss: 2.7440e-14 - mul_24_loss: 3.6525e-17\n",
      "Epoch 446/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.1468 - u_loss: 3.1468 - sub_4_loss: 2.7178e-14 - mul_24_loss: 3.6211e-17\n",
      "Epoch 447/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.1358 - u_loss: 3.1358 - sub_4_loss: 2.6763e-14 - mul_24_loss: 3.5750e-17\n",
      "Epoch 448/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.1248 - u_loss: 3.1248 - sub_4_loss: 2.6593e-14 - mul_24_loss: 3.5538e-17\n",
      "Epoch 449/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.1137 - u_loss: 3.1137 - sub_4_loss: 2.6365e-14 - mul_24_loss: 3.5255e-17\n",
      "Epoch 450/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.1029 - u_loss: 3.1029 - sub_4_loss: 2.5970e-14 - mul_24_loss: 3.4824e-17\n",
      "Epoch 451/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.0919 - u_loss: 3.0919 - sub_4_loss: 2.5859e-14 - mul_24_loss: 3.4672e-17\n",
      "Epoch 452/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.0811 - u_loss: 3.0811 - sub_4_loss: 2.5514e-14 - mul_24_loss: 3.4284e-17\n",
      "Epoch 453/2500\n",
      "10/10 [==============================] - ETA: 0s - batch: 4.5000 - size: 5000.0000 - loss: 3.0701 - u_loss: 3.0701 - sub_4_loss: 2.5305e-14 - mul_24_loss: 3.4022e-1 - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.0701 - u_loss: 3.0701 - sub_4_loss: 2.5305e-14 - mul_24_loss: 3.4022e-17\n",
      "Epoch 454/2500\n",
      "10/10 [==============================] - 2s 157ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.0592 - u_loss: 3.0592 - sub_4_loss: 2.5041e-14 - mul_24_loss: 3.3717e-17\n",
      "Epoch 455/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.0484 - u_loss: 3.0484 - sub_4_loss: 2.4789e-14 - mul_24_loss: 3.3419e-17\n",
      "Epoch 456/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.0377 - u_loss: 3.0377 - sub_4_loss: 2.4507e-14 - mul_24_loss: 3.3100e-17\n",
      "Epoch 457/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.0269 - u_loss: 3.0269 - sub_4_loss: 2.4324e-14 - mul_24_loss: 3.2873e-17\n",
      "Epoch 458/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.0161 - u_loss: 3.0161 - sub_4_loss: 2.4079e-14 - mul_24_loss: 3.2586e-17\n",
      "Epoch 459/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 3.0056 - u_loss: 3.0056 - sub_4_loss: 2.3755e-14 - mul_24_loss: 3.2211e-17\n",
      "Epoch 460/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.9948 - u_loss: 2.9948 - sub_4_loss: 2.3500e-14 - mul_24_loss: 3.1916e-17\n",
      "Epoch 461/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.9843 - u_loss: 2.9843 - sub_4_loss: 2.3265e-14 - mul_24_loss: 3.1643e-17\n",
      "Epoch 462/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.9736 - u_loss: 2.9736 - sub_4_loss: 2.3040e-14 - mul_24_loss: 3.1370e-17\n",
      "Epoch 463/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.9630 - u_loss: 2.9630 - sub_4_loss: 2.2865e-14 - mul_24_loss: 3.1154e-17\n",
      "Epoch 464/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.9527 - u_loss: 2.9527 - sub_4_loss: 2.2546e-14 - mul_24_loss: 3.0795e-17\n",
      "Epoch 465/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.9420 - u_loss: 2.9420 - sub_4_loss: 2.2317e-14 - mul_24_loss: 3.0528e-17\n",
      "Epoch 466/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.9317 - u_loss: 2.9317 - sub_4_loss: 2.2109e-14 - mul_24_loss: 3.0265e-17\n",
      "Epoch 467/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.9211 - u_loss: 2.9211 - sub_4_loss: 2.1932e-14 - mul_24_loss: 3.0057e-17\n",
      "Epoch 468/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.9107 - u_loss: 2.9107 - sub_4_loss: 2.1681e-14 - mul_24_loss: 2.9754e-17\n",
      "Epoch 469/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.9004 - u_loss: 2.9004 - sub_4_loss: 2.1376e-14 - mul_24_loss: 2.9407e-17\n",
      "Epoch 470/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.8900 - u_loss: 2.8900 - sub_4_loss: 2.1127e-14 - mul_24_loss: 2.9117e-17\n",
      "Epoch 471/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.8798 - u_loss: 2.8798 - sub_4_loss: 2.1005e-14 - mul_24_loss: 2.8954e-17\n",
      "Epoch 472/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.8695 - u_loss: 2.8695 - sub_4_loss: 2.0733e-14 - mul_24_loss: 2.8633e-17\n",
      "Epoch 473/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.8592 - u_loss: 2.8592 - sub_4_loss: 2.0443e-14 - mul_24_loss: 2.8298e-17\n",
      "Epoch 474/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.8491 - u_loss: 2.8491 - sub_4_loss: 2.0262e-14 - mul_24_loss: 2.8092e-17\n",
      "Epoch 475/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.8390 - u_loss: 2.8390 - sub_4_loss: 2.0075e-14 - mul_24_loss: 2.7853e-17\n",
      "Epoch 476/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.8288 - u_loss: 2.8288 - sub_4_loss: 1.9827e-14 - mul_24_loss: 2.7571e-17\n",
      "Epoch 477/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.8186 - u_loss: 2.8186 - sub_4_loss: 1.9592e-14 - mul_24_loss: 2.7284e-17\n",
      "Epoch 478/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.8086 - u_loss: 2.8086 - sub_4_loss: 1.9437e-14 - mul_24_loss: 2.7094e-17\n",
      "Epoch 479/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.7985 - u_loss: 2.7985 - sub_4_loss: 1.9239e-14 - mul_24_loss: 2.6851e-17\n",
      "Epoch 480/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.7886 - u_loss: 2.7886 - sub_4_loss: 1.9027e-14 - mul_24_loss: 2.6600e-17\n",
      "Epoch 481/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.7787 - u_loss: 2.7787 - sub_4_loss: 1.8808e-14 - mul_24_loss: 2.6331e-17\n",
      "Epoch 482/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.7686 - u_loss: 2.7686 - sub_4_loss: 1.8555e-14 - mul_24_loss: 2.6045e-17\n",
      "Epoch 483/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.7588 - u_loss: 2.7588 - sub_4_loss: 1.8372e-14 - mul_24_loss: 2.5820e-17\n",
      "Epoch 484/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.7489 - u_loss: 2.7489 - sub_4_loss: 1.8148e-14 - mul_24_loss: 2.5555e-17\n",
      "Epoch 485/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.7390 - u_loss: 2.7390 - sub_4_loss: 1.7986e-14 - mul_24_loss: 2.5359e-17\n",
      "Epoch 486/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.7291 - u_loss: 2.7291 - sub_4_loss: 1.7758e-14 - mul_24_loss: 2.5095e-17\n",
      "Epoch 487/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.7196 - u_loss: 2.7196 - sub_4_loss: 1.7510e-14 - mul_24_loss: 2.4798e-17\n",
      "Epoch 488/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.7097 - u_loss: 2.7097 - sub_4_loss: 1.7392e-14 - mul_24_loss: 2.4640e-17\n",
      "Epoch 489/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.6999 - u_loss: 2.6999 - sub_4_loss: 1.7209e-14 - mul_24_loss: 2.4413e-17\n",
      "Epoch 490/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.6904 - u_loss: 2.6904 - sub_4_loss: 1.6997e-14 - mul_24_loss: 2.4162e-17\n",
      "Epoch 491/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.6808 - u_loss: 2.6808 - sub_4_loss: 1.6728e-14 - mul_24_loss: 2.3849e-17\n",
      "Epoch 492/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.6711 - u_loss: 2.6711 - sub_4_loss: 1.6599e-14 - mul_24_loss: 2.3686e-17\n",
      "Epoch 493/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.6616 - u_loss: 2.6616 - sub_4_loss: 1.6444e-14 - mul_24_loss: 2.3494e-17\n",
      "Epoch 494/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.6520 - u_loss: 2.6520 - sub_4_loss: 1.6176e-14 - mul_24_loss: 2.3184e-17\n",
      "Epoch 495/2500\n",
      "10/10 [==============================] - 2s 156ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.6426 - u_loss: 2.6426 - sub_4_loss: 1.6062e-14 - mul_24_loss: 2.3034e-17\n",
      "Epoch 496/2500\n",
      "10/10 [==============================] - 2s 158ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.6330 - u_loss: 2.6330 - sub_4_loss: 1.5814e-14 - mul_24_loss: 2.2738e-17\n",
      "Epoch 497/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.6237 - u_loss: 2.6237 - sub_4_loss: 1.5644e-14 - mul_24_loss: 2.2537e-17\n",
      "Epoch 498/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.6141 - u_loss: 2.6141 - sub_4_loss: 1.5476e-14 - mul_24_loss: 2.2327e-17\n",
      "Epoch 499/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.6050 - u_loss: 2.6050 - sub_4_loss: 1.5321e-14 - mul_24_loss: 2.2135e-17\n",
      "Epoch 500/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.5956 - u_loss: 2.5956 - sub_4_loss: 1.5089e-14 - mul_24_loss: 2.1859e-17\n",
      "Epoch 501/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.5863 - u_loss: 2.5863 - sub_4_loss: 1.4952e-14 - mul_24_loss: 2.1681e-17\n",
      "Epoch 502/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.5770 - u_loss: 2.5770 - sub_4_loss: 1.4736e-14 - mul_24_loss: 2.1433e-17\n",
      "Epoch 503/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.5678 - u_loss: 2.5678 - sub_4_loss: 1.4582e-14 - mul_24_loss: 2.1237e-17\n",
      "Epoch 504/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.5587 - u_loss: 2.5587 - sub_4_loss: 1.4467e-14 - mul_24_loss: 2.1092e-17\n",
      "Epoch 505/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.5495 - u_loss: 2.5495 - sub_4_loss: 1.4229e-14 - mul_24_loss: 2.0809e-17\n",
      "Epoch 506/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.5403 - u_loss: 2.5403 - sub_4_loss: 1.4097e-14 - mul_24_loss: 2.0633e-17\n",
      "Epoch 507/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.5314 - u_loss: 2.5314 - sub_4_loss: 1.3945e-14 - mul_24_loss: 2.0455e-17\n",
      "Epoch 508/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.5221 - u_loss: 2.5221 - sub_4_loss: 1.3706e-14 - mul_24_loss: 2.0171e-17\n",
      "Epoch 509/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.5131 - u_loss: 2.5131 - sub_4_loss: 1.3569e-14 - mul_24_loss: 2.0001e-17\n",
      "Epoch 510/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.5043 - u_loss: 2.5043 - sub_4_loss: 1.3430e-14 - mul_24_loss: 1.9826e-17\n",
      "Epoch 511/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.4954 - u_loss: 2.4954 - sub_4_loss: 1.3298e-14 - mul_24_loss: 1.9657e-17\n",
      "Epoch 512/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.4863 - u_loss: 2.4863 - sub_4_loss: 1.3130e-14 - mul_24_loss: 1.9450e-17\n",
      "Epoch 513/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.4775 - u_loss: 2.4775 - sub_4_loss: 1.2972e-14 - mul_24_loss: 1.9255e-17\n",
      "Epoch 514/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.4687 - u_loss: 2.4687 - sub_4_loss: 1.2777e-14 - mul_24_loss: 1.9021e-17\n",
      "Epoch 515/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.4598 - u_loss: 2.4598 - sub_4_loss: 1.2611e-14 - mul_24_loss: 1.8813e-17\n",
      "Epoch 516/2500\n",
      "10/10 [==============================] - 2s 156ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.4510 - u_loss: 2.4510 - sub_4_loss: 1.2461e-14 - mul_24_loss: 1.8632e-17\n",
      "Epoch 517/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.4425 - u_loss: 2.4425 - sub_4_loss: 1.2289e-14 - mul_24_loss: 1.8419e-17\n",
      "Epoch 518/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.4336 - u_loss: 2.4336 - sub_4_loss: 1.2166e-14 - mul_24_loss: 1.8263e-17\n",
      "Epoch 519/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.4250 - u_loss: 2.4250 - sub_4_loss: 1.2070e-14 - mul_24_loss: 1.8140e-17\n",
      "Epoch 520/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.4165 - u_loss: 2.4165 - sub_4_loss: 1.1838e-14 - mul_24_loss: 1.7859e-17\n",
      "Epoch 521/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.4079 - u_loss: 2.4079 - sub_4_loss: 1.1682e-14 - mul_24_loss: 1.7665e-17\n",
      "Epoch 522/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.3991 - u_loss: 2.3991 - sub_4_loss: 1.1534e-14 - mul_24_loss: 1.7483e-17\n",
      "Epoch 523/2500\n",
      "10/10 [==============================] - 2s 160ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.3907 - u_loss: 2.3907 - sub_4_loss: 1.1394e-14 - mul_24_loss: 1.7307e-17\n",
      "Epoch 524/2500\n",
      "10/10 [==============================] - 2s 159ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.3821 - u_loss: 2.3821 - sub_4_loss: 1.1279e-14 - mul_24_loss: 1.7159e-17\n",
      "Epoch 525/2500\n",
      "10/10 [==============================] - 2s 162ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.3738 - u_loss: 2.3738 - sub_4_loss: 1.1109e-14 - mul_24_loss: 1.6954e-17\n",
      "Epoch 526/2500\n",
      "10/10 [==============================] - 2s 159ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.3655 - u_loss: 2.3655 - sub_4_loss: 1.1000e-14 - mul_24_loss: 1.6807e-17\n",
      "Epoch 527/2500\n",
      "10/10 [==============================] - 2s 156ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.3570 - u_loss: 2.3570 - sub_4_loss: 1.0870e-14 - mul_24_loss: 1.6644e-17\n",
      "Epoch 528/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.3486 - u_loss: 2.3486 - sub_4_loss: 1.0734e-14 - mul_24_loss: 1.6466e-17\n",
      "Epoch 529/2500\n",
      "10/10 [==============================] - 2s 156ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.3403 - u_loss: 2.3403 - sub_4_loss: 1.0558e-14 - mul_24_loss: 1.6254e-17\n",
      "Epoch 530/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.3320 - u_loss: 2.3320 - sub_4_loss: 1.0457e-14 - mul_24_loss: 1.6121e-17\n",
      "Epoch 531/2500\n",
      "10/10 [==============================] - 2s 158ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.3238 - u_loss: 2.3238 - sub_4_loss: 1.0331e-14 - mul_24_loss: 1.5964e-17\n",
      "Epoch 532/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.3156 - u_loss: 2.3156 - sub_4_loss: 1.0180e-14 - mul_24_loss: 1.5774e-17\n",
      "Epoch 533/2500\n",
      "10/10 [==============================] - 2s 157ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.3074 - u_loss: 2.3074 - sub_4_loss: 1.0015e-14 - mul_24_loss: 1.5573e-17\n",
      "Epoch 534/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.2992 - u_loss: 2.2992 - sub_4_loss: 9.9136e-15 - mul_24_loss: 1.5436e-17\n",
      "Epoch 535/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.2912 - u_loss: 2.2912 - sub_4_loss: 9.8085e-15 - mul_24_loss: 1.5299e-17\n",
      "Epoch 536/2500\n",
      "10/10 [==============================] - 2s 156ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.2833 - u_loss: 2.2833 - sub_4_loss: 9.6210e-15 - mul_24_loss: 1.5073e-17\n",
      "Epoch 537/2500\n",
      "10/10 [==============================] - 2s 160ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.2751 - u_loss: 2.2751 - sub_4_loss: 9.5701e-15 - mul_24_loss: 1.4996e-17\n",
      "Epoch 538/2500\n",
      "10/10 [==============================] - 2s 157ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.2671 - u_loss: 2.2671 - sub_4_loss: 9.3910e-15 - mul_24_loss: 1.4779e-17\n",
      "Epoch 539/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.2592 - u_loss: 2.2592 - sub_4_loss: 9.3101e-15 - mul_24_loss: 1.4665e-17\n",
      "Epoch 540/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.2511 - u_loss: 2.2511 - sub_4_loss: 9.1455e-15 - mul_24_loss: 1.4466e-17\n",
      "Epoch 541/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.2435 - u_loss: 2.2435 - sub_4_loss: 9.0669e-15 - mul_24_loss: 1.4357e-17\n",
      "Epoch 542/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.2355 - u_loss: 2.2355 - sub_4_loss: 8.9102e-15 - mul_24_loss: 1.4167e-17\n",
      "Epoch 543/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.2277 - u_loss: 2.2277 - sub_4_loss: 8.8055e-15 - mul_24_loss: 1.4028e-17\n",
      "Epoch 544/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.2199 - u_loss: 2.2199 - sub_4_loss: 8.7272e-15 - mul_24_loss: 1.3923e-17\n",
      "Epoch 545/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.2122 - u_loss: 2.2122 - sub_4_loss: 8.5924e-15 - mul_24_loss: 1.3752e-17\n",
      "Epoch 546/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.2044 - u_loss: 2.2044 - sub_4_loss: 8.4730e-15 - mul_24_loss: 1.3600e-17\n",
      "Epoch 547/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1969 - u_loss: 2.1969 - sub_4_loss: 8.3454e-15 - mul_24_loss: 1.3434e-17\n",
      "Epoch 548/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1893 - u_loss: 2.1893 - sub_4_loss: 8.2381e-15 - mul_24_loss: 1.3300e-17\n",
      "Epoch 549/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1816 - u_loss: 2.1816 - sub_4_loss: 8.1295e-15 - mul_24_loss: 1.3161e-17\n",
      "Epoch 550/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1740 - u_loss: 2.1740 - sub_4_loss: 8.0409e-15 - mul_24_loss: 1.3040e-17\n",
      "Epoch 551/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1665 - u_loss: 2.1665 - sub_4_loss: 7.9314e-15 - mul_24_loss: 1.2895e-17\n",
      "Epoch 552/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1589 - u_loss: 2.1589 - sub_4_loss: 7.8403e-15 - mul_24_loss: 1.2779e-17\n",
      "Epoch 553/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1516 - u_loss: 2.1516 - sub_4_loss: 7.7036e-15 - mul_24_loss: 1.2607e-17\n",
      "Epoch 554/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1441 - u_loss: 2.1441 - sub_4_loss: 7.6278e-15 - mul_24_loss: 1.2501e-17\n",
      "Epoch 555/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1367 - u_loss: 2.1367 - sub_4_loss: 7.4549e-15 - mul_24_loss: 1.2284e-17\n",
      "Epoch 556/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1294 - u_loss: 2.1294 - sub_4_loss: 7.3896e-15 - mul_24_loss: 1.2192e-17\n",
      "Epoch 557/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1221 - u_loss: 2.1221 - sub_4_loss: 7.2981e-15 - mul_24_loss: 1.2072e-17\n",
      "Epoch 558/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1147 - u_loss: 2.1147 - sub_4_loss: 7.1772e-15 - mul_24_loss: 1.1917e-17\n",
      "Epoch 559/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1076 - u_loss: 2.1076 - sub_4_loss: 7.0674e-15 - mul_24_loss: 1.1773e-17\n",
      "Epoch 560/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.1003 - u_loss: 2.1003 - sub_4_loss: 7.0059e-15 - mul_24_loss: 1.1688e-17\n",
      "Epoch 561/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0932 - u_loss: 2.0932 - sub_4_loss: 6.8907e-15 - mul_24_loss: 1.1539e-17\n",
      "Epoch 562/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0860 - u_loss: 2.0860 - sub_4_loss: 6.7836e-15 - mul_24_loss: 1.1399e-17\n",
      "Epoch 563/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0790 - u_loss: 2.0790 - sub_4_loss: 6.6801e-15 - mul_24_loss: 1.1260e-17\n",
      "Epoch 564/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0719 - u_loss: 2.0719 - sub_4_loss: 6.5881e-15 - mul_24_loss: 1.1143e-17\n",
      "Epoch 565/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0649 - u_loss: 2.0649 - sub_4_loss: 6.4924e-15 - mul_24_loss: 1.1011e-17\n",
      "Epoch 566/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0578 - u_loss: 2.0578 - sub_4_loss: 6.4091e-15 - mul_24_loss: 1.0904e-17\n",
      "Epoch 567/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0509 - u_loss: 2.0509 - sub_4_loss: 6.3074e-15 - mul_24_loss: 1.0767e-17\n",
      "Epoch 568/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0439 - u_loss: 2.0439 - sub_4_loss: 6.2207e-15 - mul_24_loss: 1.0654e-17\n",
      "Epoch 569/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0371 - u_loss: 2.0371 - sub_4_loss: 6.1427e-15 - mul_24_loss: 1.0547e-17\n",
      "Epoch 570/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0302 - u_loss: 2.0303 - sub_4_loss: 6.0576e-15 - mul_24_loss: 1.0434e-17\n",
      "Epoch 571/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0234 - u_loss: 2.0234 - sub_4_loss: 5.9740e-15 - mul_24_loss: 1.0323e-17\n",
      "Epoch 572/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0166 - u_loss: 2.0166 - sub_4_loss: 5.9066e-15 - mul_24_loss: 1.0231e-17\n",
      "Epoch 573/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0098 - u_loss: 2.0098 - sub_4_loss: 5.8250e-15 - mul_24_loss: 1.0115e-17\n",
      "Epoch 574/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 2.0032 - u_loss: 2.0032 - sub_4_loss: 5.7097e-15 - mul_24_loss: 9.9658e-18\n",
      "Epoch 575/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9965 - u_loss: 1.9965 - sub_4_loss: 5.6562e-15 - mul_24_loss: 9.8903e-18\n",
      "Epoch 576/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9899 - u_loss: 1.9899 - sub_4_loss: 5.5813e-15 - mul_24_loss: 9.7899e-18\n",
      "Epoch 577/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9832 - u_loss: 1.9832 - sub_4_loss: 5.4778e-15 - mul_24_loss: 9.6502e-18\n",
      "Epoch 578/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9766 - u_loss: 1.9766 - sub_4_loss: 5.4130e-15 - mul_24_loss: 9.5629e-18\n",
      "Epoch 579/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9702 - u_loss: 1.9702 - sub_4_loss: 5.3118e-15 - mul_24_loss: 9.4263e-18\n",
      "Epoch 580/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9637 - u_loss: 1.9637 - sub_4_loss: 5.2504e-15 - mul_24_loss: 9.3399e-18\n",
      "Epoch 581/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9573 - u_loss: 1.9573 - sub_4_loss: 5.1581e-15 - mul_24_loss: 9.2182e-18\n",
      "Epoch 582/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9507 - u_loss: 1.9507 - sub_4_loss: 5.0890e-15 - mul_24_loss: 9.1216e-18\n",
      "Epoch 583/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9443 - u_loss: 1.9443 - sub_4_loss: 5.0084e-15 - mul_24_loss: 9.0115e-18\n",
      "Epoch 584/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9380 - u_loss: 1.9380 - sub_4_loss: 4.9536e-15 - mul_24_loss: 8.9308e-18\n",
      "Epoch 585/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9317 - u_loss: 1.9317 - sub_4_loss: 4.8641e-15 - mul_24_loss: 8.8095e-18\n",
      "Epoch 586/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9253 - u_loss: 1.9253 - sub_4_loss: 4.8003e-15 - mul_24_loss: 8.7230e-18\n",
      "Epoch 587/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9191 - u_loss: 1.9191 - sub_4_loss: 4.7372e-15 - mul_24_loss: 8.6355e-18\n",
      "Epoch 588/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9131 - u_loss: 1.9131 - sub_4_loss: 4.6694e-15 - mul_24_loss: 8.5397e-18\n",
      "Epoch 589/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9067 - u_loss: 1.9067 - sub_4_loss: 4.6024e-15 - mul_24_loss: 8.4487e-18\n",
      "Epoch 590/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.9007 - u_loss: 1.9007 - sub_4_loss: 4.5151e-15 - mul_24_loss: 8.3250e-18\n",
      "Epoch 591/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8944 - u_loss: 1.8944 - sub_4_loss: 4.4557e-15 - mul_24_loss: 8.2431e-18\n",
      "Epoch 592/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8883 - u_loss: 1.8883 - sub_4_loss: 4.3877e-15 - mul_24_loss: 8.1473e-18\n",
      "Epoch 593/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8824 - u_loss: 1.8824 - sub_4_loss: 4.3094e-15 - mul_24_loss: 8.0423e-18\n",
      "Epoch 594/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8764 - u_loss: 1.8764 - sub_4_loss: 4.2516e-15 - mul_24_loss: 7.9598e-18\n",
      "Epoch 595/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8704 - u_loss: 1.8704 - sub_4_loss: 4.1986e-15 - mul_24_loss: 7.8835e-18\n",
      "Epoch 596/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8644 - u_loss: 1.8644 - sub_4_loss: 4.1444e-15 - mul_24_loss: 7.8050e-18\n",
      "Epoch 597/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8586 - u_loss: 1.8586 - sub_4_loss: 4.0782e-15 - mul_24_loss: 7.7114e-18\n",
      "Epoch 598/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8526 - u_loss: 1.8526 - sub_4_loss: 4.0219e-15 - mul_24_loss: 7.6314e-18\n",
      "Epoch 599/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8467 - u_loss: 1.8467 - sub_4_loss: 3.9551e-15 - mul_24_loss: 7.5380e-18\n",
      "Epoch 600/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8411 - u_loss: 1.8411 - sub_4_loss: 3.8896e-15 - mul_24_loss: 7.4455e-18\n",
      "Epoch 601/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8352 - u_loss: 1.8352 - sub_4_loss: 3.8441e-15 - mul_24_loss: 7.3796e-18\n",
      "Epoch 602/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8295 - u_loss: 1.8295 - sub_4_loss: 3.7621e-15 - mul_24_loss: 7.2644e-18\n",
      "Epoch 603/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8238 - u_loss: 1.8238 - sub_4_loss: 3.7244e-15 - mul_24_loss: 7.2058e-18\n",
      "Epoch 604/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8182 - u_loss: 1.8182 - sub_4_loss: 3.6553e-15 - mul_24_loss: 7.1094e-18\n",
      "Epoch 605/2500\n",
      "10/10 [==============================] - 2s 152ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8125 - u_loss: 1.8125 - sub_4_loss: 3.5990e-15 - mul_24_loss: 7.0280e-18\n",
      "Epoch 606/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8069 - u_loss: 1.8069 - sub_4_loss: 3.5498e-15 - mul_24_loss: 6.9555e-18\n",
      "Epoch 607/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.8013 - u_loss: 1.8013 - sub_4_loss: 3.5051e-15 - mul_24_loss: 6.8898e-18\n",
      "Epoch 608/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7958 - u_loss: 1.7958 - sub_4_loss: 3.4240e-15 - mul_24_loss: 6.7761e-18\n",
      "Epoch 609/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7904 - u_loss: 1.7904 - sub_4_loss: 3.3911e-15 - mul_24_loss: 6.7264e-18\n",
      "Epoch 610/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7848 - u_loss: 1.7848 - sub_4_loss: 3.3235e-15 - mul_24_loss: 6.6283e-18\n",
      "Epoch 611/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7795 - u_loss: 1.7795 - sub_4_loss: 3.2807e-15 - mul_24_loss: 6.5644e-18\n",
      "Epoch 612/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7741 - u_loss: 1.7741 - sub_4_loss: 3.2393e-15 - mul_24_loss: 6.5038e-18\n",
      "Epoch 613/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7687 - u_loss: 1.7687 - sub_4_loss: 3.1722e-15 - mul_24_loss: 6.4054e-18\n",
      "Epoch 614/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7633 - u_loss: 1.7633 - sub_4_loss: 3.1277e-15 - mul_24_loss: 6.3388e-18\n",
      "Epoch 615/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7581 - u_loss: 1.7581 - sub_4_loss: 3.0900e-15 - mul_24_loss: 6.2838e-18\n",
      "Epoch 616/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7528 - u_loss: 1.7528 - sub_4_loss: 3.0241e-15 - mul_24_loss: 6.1865e-18\n",
      "Epoch 617/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7476 - u_loss: 1.7476 - sub_4_loss: 2.9959e-15 - mul_24_loss: 6.1426e-18\n",
      "Epoch 618/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7425 - u_loss: 1.7425 - sub_4_loss: 2.9373e-15 - mul_24_loss: 6.0568e-18\n",
      "Epoch 619/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7373 - u_loss: 1.7373 - sub_4_loss: 2.8940e-15 - mul_24_loss: 5.9916e-18\n",
      "Epoch 620/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7322 - u_loss: 1.7322 - sub_4_loss: 2.8611e-15 - mul_24_loss: 5.9418e-18\n",
      "Epoch 621/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7269 - u_loss: 1.7269 - sub_4_loss: 2.8043e-15 - mul_24_loss: 5.8580e-18\n",
      "Epoch 622/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7221 - u_loss: 1.7221 - sub_4_loss: 2.7664e-15 - mul_24_loss: 5.7995e-18\n",
      "Epoch 623/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7171 - u_loss: 1.7171 - sub_4_loss: 2.7181e-15 - mul_24_loss: 5.7266e-18\n",
      "Epoch 624/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7119 - u_loss: 1.7119 - sub_4_loss: 2.6735e-15 - mul_24_loss: 5.6596e-18\n",
      "Epoch 625/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7070 - u_loss: 1.7070 - sub_4_loss: 2.6372e-15 - mul_24_loss: 5.6030e-18\n",
      "Epoch 626/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.7021 - u_loss: 1.7021 - sub_4_loss: 2.5880e-15 - mul_24_loss: 5.5279e-18\n",
      "Epoch 627/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6973 - u_loss: 1.6973 - sub_4_loss: 2.5565e-15 - mul_24_loss: 5.4797e-18\n",
      "Epoch 628/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6924 - u_loss: 1.6924 - sub_4_loss: 2.5168e-15 - mul_24_loss: 5.4190e-18\n",
      "Epoch 629/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6875 - u_loss: 1.6875 - sub_4_loss: 2.4744e-15 - mul_24_loss: 5.3532e-18\n",
      "Epoch 630/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6828 - u_loss: 1.6828 - sub_4_loss: 2.4338e-15 - mul_24_loss: 5.2903e-18\n",
      "Epoch 631/2500\n",
      "10/10 [==============================] - 2s 153ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6780 - u_loss: 1.6780 - sub_4_loss: 2.3926e-15 - mul_24_loss: 5.2264e-18\n",
      "Epoch 632/2500\n",
      "10/10 [==============================] - 2s 156ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6733 - u_loss: 1.6733 - sub_4_loss: 2.3586e-15 - mul_24_loss: 5.1734e-18\n",
      "Epoch 633/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6685 - u_loss: 1.6685 - sub_4_loss: 2.3234e-15 - mul_24_loss: 5.1189e-18\n",
      "Epoch 634/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6639 - u_loss: 1.6639 - sub_4_loss: 2.2856e-15 - mul_24_loss: 5.0595e-18\n",
      "Epoch 635/2500\n",
      "10/10 [==============================] - 2s 161ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6593 - u_loss: 1.6593 - sub_4_loss: 2.2386e-15 - mul_24_loss: 4.9854e-18\n",
      "Epoch 636/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6547 - u_loss: 1.6547 - sub_4_loss: 2.2066e-15 - mul_24_loss: 4.9350e-18\n",
      "Epoch 637/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6501 - u_loss: 1.6501 - sub_4_loss: 2.1782e-15 - mul_24_loss: 4.8898e-18\n",
      "Epoch 638/2500\n",
      "10/10 [==============================] - 2s 158ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6456 - u_loss: 1.6456 - sub_4_loss: 2.1386e-15 - mul_24_loss: 4.8267e-18\n",
      "Epoch 639/2500\n",
      "10/10 [==============================] - 2s 157ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6411 - u_loss: 1.6411 - sub_4_loss: 2.1043e-15 - mul_24_loss: 4.7728e-18\n",
      "Epoch 640/2500\n",
      "10/10 [==============================] - 2s 159ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6367 - u_loss: 1.6367 - sub_4_loss: 2.0732e-15 - mul_24_loss: 4.7231e-18\n",
      "Epoch 641/2500\n",
      "10/10 [==============================] - 2s 163ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6322 - u_loss: 1.6322 - sub_4_loss: 2.0436e-15 - mul_24_loss: 4.6761e-18\n",
      "Epoch 642/2500\n",
      "10/10 [==============================] - 2s 155ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6279 - u_loss: 1.6279 - sub_4_loss: 2.0038e-15 - mul_24_loss: 4.6109e-18\n",
      "Epoch 643/2500\n",
      "10/10 [==============================] - 2s 156ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6234 - u_loss: 1.6234 - sub_4_loss: 1.9737e-15 - mul_24_loss: 4.5621e-18\n",
      "Epoch 644/2500\n",
      "10/10 [==============================] - 2s 154ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6191 - u_loss: 1.6191 - sub_4_loss: 1.9423e-15 - mul_24_loss: 4.5122e-18\n",
      "Epoch 645/2500\n",
      "10/10 [==============================] - 2s 159ms/step - batch: 4.5000 - size: 5000.0000 - loss: 1.6148 - u_loss: 1.6148 - sub_4_loss: 1.9194e-15 - mul_24_loss: 4.4747e-18\n",
      "Epoch 646/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/10 [====================>.........] - ETA: 0s - batch: 3.0000 - size: 5000.0000 - loss: 1.5388 - u_loss: 1.5388 - sub_4_loss: 7.1442e-16 - mul_24_loss: 1.2816e-18"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c75bfcce8d30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         history = m.train([x_data,  t_data], [(indices,datos)]+2*['zeros'], epochs =epochs,verbose=1,\n\u001b[1;32m---> 96\u001b[1;33m                         batch_size=batch_size)\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[0mTEntrenamiento\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sciann\\models\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_true, y_true, weights, target_weights, batch_size, epochs, learning_rate, adaptive_weights, adaptive_sample_weights, log_loss_gradients, shuffle, callbacks, stop_lr_value, reduce_lr_after, reduce_lr_min_delta, stop_after, stop_loss_value, log_parameters, log_functionals, log_loss_landscape, save_weights, default_zero_weight, validation_data, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msci_callbacks\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m         )\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1087\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3824\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3825\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3826\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3827\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19min 5s (started: 2021-08-03 13:26:49 +02:00)\n"
     ]
    }
   ],
   "source": [
    "# resultados  = []\n",
    "for configuracion in configuraciones_restantes:\n",
    "    with mlflow.start_run():\n",
    "        #Parámetros\n",
    "        #################\n",
    "        trainpt = configuracion[0]\n",
    "        u_Structure = configuracion[1]\n",
    "        u_Activator = configuracion[2]\n",
    "        epochs = configuracion[3]\n",
    "        loss = configuracion[4]\n",
    "        optimizer = configuracion[5]\n",
    "        batch_size = configuracion[6]\n",
    "        #################\n",
    "\n",
    "\n",
    "        #Log de parámetros\n",
    "        #################\n",
    "        mlflow.log_param('Point_Density', trainpt)\n",
    "        len_str = len(u_Structure)\n",
    "        num_neu = u_Structure[0]\n",
    "        print_str =  str(len_str) + '[' + str(num_neu) + ']'\n",
    "        mlflow.log_param('u_Structure', print_str)\n",
    "        mlflow.log_param('u_Activator', u_Activator)\n",
    "        mlflow.log_param('Epochs', epochs)\n",
    "        mlflow.log_param('Loss', loss)\n",
    "        mlflow.log_param('Optimizer', optimizer)\n",
    "        mlflow.log_param('Batch size', batch_size)\n",
    "        #################\n",
    "\n",
    "        #Variables del modelo\n",
    "        #################\n",
    "        x = sn.Variable('x')\n",
    "        t = sn.Variable('t')\n",
    "        u_Structure = u_Structure\n",
    "        u_Activator = u_Activator\n",
    "        u = sn.Functional(\"u\", [x,t], u_Structure ,u_Activator)\n",
    "        #################\n",
    "\n",
    "        #Construcción del mallado\n",
    "        #################\n",
    "        denspt_t = trainpt # Densidad de puntos de evaluación de los funcionales\n",
    "        denspt_x = trainpt\n",
    "\n",
    "        xmin,xmax=0,2 # Límites en x e y\n",
    "        tmin,tmax=0,10 # Límites en tiempo t\n",
    "        xrange=xmax-xmin\n",
    "        trange=tmax-tmin\n",
    "\n",
    "        # Mallado (es una malla en tres dimensiones)\n",
    "        x_data, t_data = np.meshgrid(\n",
    "          np.linspace(xmin, xmax, xrange*denspt_x),\n",
    "          np.linspace(tmin,tmax, trange*denspt_t)\n",
    "        )\n",
    "\n",
    "        x_data = x_data.flatten()[:,None]\n",
    "        t_data = t_data.flatten()[:,None]\n",
    "\n",
    "        mlflow.log_param('Num Points', trainpt**2*xrange*trange)\n",
    "        #################\n",
    "\n",
    "\n",
    "        #Restricciones\n",
    "        #################\n",
    "        #Calor\n",
    "        L1 = sn.constraints.PDE(capCal*diff(u,t) - conductividad *( (diff(u,x,order=2) )))\n",
    "        #Aislamiento\n",
    "        LI = sn.constraints.PDE((activacion(x,TOL,-1)*conductividad*(- diff(u,x))))\n",
    "        #################\n",
    "\n",
    "        #Datos introducidos como puntos\n",
    "        #################\n",
    "        #TInicial\n",
    "        indInicial = np.where(t_data<TOL)[0]\n",
    "        calorInicial = focoTemp * np.exp(-(x_data[indInicial,0]**2)/(2*(0.1)**2))/(2*np.pi*0.1)\n",
    "        calorInicial = 2.5*x_data[indInicial,0]\n",
    "\n",
    "        #Elegimos x > 2-TOL y t>TOL\n",
    "        indDerecha = np.where(x_data>2-TOL)[0]\n",
    "        indT_No_Inicial = np.where(t_data>TOL)[0]\n",
    "        indDerecha = np.intersect1d(indDerecha,indT_No_Inicial)\n",
    "        calorDerecha = np.full(len(indDerecha),tempExt)\n",
    "\n",
    "        #Unimos todos los datos\n",
    "        indices = np.concatenate((indInicial,indDerecha))[:,None]\n",
    "        datos = np.concatenate((calorInicial,calorDerecha))[:,None]\n",
    "\n",
    "        d1 = sn.constraints.Data(u)\n",
    "        #################\n",
    "\n",
    "        #Construcción del modelo\n",
    "        m = sn.SciModel ([x,t], [d1,L1,LI],loss,optimizer)\n",
    "\n",
    "        #Entrenamiento del modelo\n",
    "        start = time.process_time()\n",
    "        history = m.train([x_data,  t_data], [(indices,datos)]+2*['zeros'], epochs =epochs,verbose=1,\n",
    "                        batch_size=batch_size)\n",
    "        TEntrenamiento = time.process_time() - start\n",
    "\n",
    "        #Testeo del modelo:\n",
    "\n",
    "        #predicciones de sciann\n",
    "\n",
    "        start2 = time.process_time()\n",
    "        u_pred_sciann =  u.eval(m, [x_test, t_test])\n",
    "        TTesteo = time.process_time() - start2\n",
    "\n",
    "        MAE = np.mean(np.abs(u_pred_Simb-u_pred_sciann))*40\n",
    "        RMSE = np.sqrt(np.mean((u_pred_Simb-u_pred_sciann)**2))*40\n",
    "\n",
    "        pred = m.model.predict([np.reshape(x_test,(-1,)),np.reshape(t_test,(-1,))])\n",
    "\n",
    "        funcional = np.mean(np.abs(np.array(pred[1])))\n",
    "\n",
    "        MAX = np.max(np.abs(u_pred_Simb-u_pred_sciann))\n",
    "\n",
    "        mlflow.log_metric('L1',MAE)\n",
    "        mlflow.log_metric('L2',RMSE)\n",
    "        mlflow.log_metric('MaxError',MAX)\n",
    "        mlflow.log_metric('Funcional',funcional)\n",
    "        mlflow.log_metric('Tiempo_Entrenamiento',TEntrenamiento)\n",
    "        mlflow.log_metric('Tiempo_Evaluacion',TTesteo)\n",
    "        configuraciones_finalizadas.append(configuracion)\n",
    "        np.save('configuraciones_finalizadas',configuraciones_finalizadas,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gg5hYxykJ4Iq",
    "outputId": "07f75ba1-8e23-48b9-9b86-7b8693147deb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 578 ms (started: 2021-07-28 19:13:44 +02:00)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-2j3EmPwKBVy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ecc8465340>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 250 ms (started: 2021-07-28 19:14:40 +02:00)\n"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "RR5v_YprLg0s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'u_loss', 'sub_86_loss', 'mul_516_loss', 'lr'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2021-07-28 19:14:33 +02:00)\n"
     ]
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wx9ITuc3LkCJ",
    "outputId": "64bba6fa-d93b-49a8-83af-97fb7cfc91c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['patata']"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fr7ytjZFLki_",
    "outputId": "483d1181-b22f-47d7-9ed9-9bd8ecaf7e1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[5, 5, 5, 5, 5], 1000, 'tanh', 0.7362768859065856, 0.04411528],\n",
       " [[5, 5, 5, 5, 5], 1000, 'relu', 0.5778696160411718, 0.1260327],\n",
       " [[6, 6, 6, 6, 6, 6], 1000, 'tanh', 0.5562344639337996, 0.14978613],\n",
       " [[6, 6, 6, 6, 6, 6], 1000, 'relu', 0.8203092842556636, 0.03137347],\n",
       " [[3, 3, 3], 1000, 'tanh', 0.6467702463624774, 0.05799583],\n",
       " [[3, 3, 3], 1000, 'relu', 0.8637267425615521, 0.045073174]]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ZjV3a5TOVaV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LoopSolver.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
